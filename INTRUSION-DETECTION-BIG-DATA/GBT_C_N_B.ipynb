{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import requests\n",
    "import time\n",
    "\n",
    "from pyspark import SQLContext, SparkContext\n",
    "from pyspark import SparkConf\n",
    "\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
    "from pyspark.ml.linalg import Vectors\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from pyspark.mllib.tree import GradientBoostedTrees, GradientBoostedTreesModel\n",
    "from pyspark.mllib.util import MLUtils\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.linalg import Vector as MLLibVector, Vectors as MLLibVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset and labels\n",
    "x=np.load('NBx.npy')\n",
    "y=np.load('NBy.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = SparkConf()\n",
    "sc = SparkContext(conf = conf)\n",
    "spark = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the rank of each feature\n",
    "R=[]\n",
    "for h in range(x.shape[1]):\n",
    "    kmeans = KMeans(init='k-means++', n_clusters=2) #The number of clusters is set to the number of classes in the dataset\n",
    "    ff=kmeans.fit_predict(x[:,h].reshape(-1,1))\n",
    "    r=metrics.homogeneity_score(y,ff) #Use the homogeneity score as a rank of the feature\n",
    "    R.append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Arrange feature accroding to thier ranks\n",
    "Rnk=np.argsort(np.array(R))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initiate the cross-validation splitter\n",
    "kfolds=StratifiedKFold(n_splits=5,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Per each set of ranks, use cross-validation to calculate accuracy.\n",
    "smr=[]\n",
    "et=0\n",
    "for j in range(Rnk.shape[0]):\n",
    "    fd=x[:,Rnk[j:]]\n",
    "    pp=0\n",
    "    lpa=np.zeros((0,2))\n",
    "    for train,test in kfolds.split(fd,y):\n",
    "        dff = map(lambda x: (int(float(x[-1])), Vectors.dense(x[:-1])),np.hstack((fd[train],y[train].reshape(-1,1))))\n",
    "        TrD = spark.createDataFrame(dff,schema=[\"label\", \"features\"]).rdd.map(lambda row: LabeledPoint(row.label, MLLibVectors.fromML(row.features)))\n",
    "        dff = map(lambda x: (int(float(x[-1])), Vectors.dense(x[:-1])),np.hstack((fd[test],y[test].reshape(-1,1))))\n",
    "        TsD = spark.createDataFrame(dff,schema=[\"label\", \"features\"]).rdd.map(lambda row: LabeledPoint(row.label, MLLibVectors.fromML(row.features)))\n",
    "        model = GradientBoostedTrees.trainClassifier(TrD,categoricalFeaturesInfo={})\n",
    "        predictions = model.predict(TsD.map(lambda x: x.features))\n",
    "        st = time.time()\n",
    "        labelsAndPredictions = TsD.map(lambda lp: lp.label).zip(predictions)\n",
    "        lpa=np.vstack((lpa,labelsAndPredictions.toDF().toPandas()))\n",
    "        et+=time.time()-st\n",
    "        acc = labelsAndPredictions.filter(lambda lp: lp[0] == lp[1]).count() / float(TsD.count())\n",
    "        pp=pp+acc\n",
    "    pp=pp/kfolds.n_splits\n",
    "    np.savetxt('F%d.csv'%j,lpa,delimiter=',')\n",
    "    smr.append([j, pp, et*1000000/x.shape[0]]) #Calculate the time required to predict a label per each object in uS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[78.0, 0.9981, 1.2401],\n",
       " [77.0, 0.9985, 1.318],\n",
       " [76.0, 0.9983, 1.2225],\n",
       " [75.0, 0.9981, 1.2223],\n",
       " [74.0, 0.9989, 1.3394],\n",
       " [73.0, 0.9981, 1.3999],\n",
       " [72.0, 0.9986, 1.1684],\n",
       " [71.0, 0.9981, 1.4243],\n",
       " [70.0, 0.9988, 1.2597],\n",
       " [69.0, 0.9986, 1.1591],\n",
       " [68.0, 0.9945, 1.231],\n",
       " [67.0, 0.9984, 1.1837],\n",
       " [66.0, 0.9987, 1.1062],\n",
       " [65.0, 0.9985, 1.0832],\n",
       " [64.0, 0.9983, 1.0804],\n",
       " [63.0, 0.9987, 1.1406],\n",
       " [62.0, 0.9983, 1.0603],\n",
       " [61.0, 0.9985, 1.0587],\n",
       " [60.0, 0.9984, 0.9506],\n",
       " [59.0, 0.9984, 1.0178],\n",
       " [58.0, 0.9984, 0.9444],\n",
       " [57.0, 0.9989, 0.9628],\n",
       " [56.0, 0.9983, 0.9401],\n",
       " [55.0, 0.999, 1.0502],\n",
       " [54.0, 0.9984, 0.9177],\n",
       " [53.0, 0.9986, 0.8377],\n",
       " [52.0, 0.9985, 0.9818],\n",
       " [51.0, 0.999, 0.9122],\n",
       " [50.0, 0.9988, 0.8652],\n",
       " [49.0, 0.9982, 0.8509],\n",
       " [48.0, 0.9985, 0.858],\n",
       " [47.0, 0.9987, 0.8618],\n",
       " [46.0, 0.9986, 0.7688],\n",
       " [45.0, 0.9988, 0.809],\n",
       " [44.0, 0.9983, 0.783],\n",
       " [43.0, 0.9986, 0.7987],\n",
       " [42.0, 0.9653, 0.7841],\n",
       " [41.0, 0.9991, 0.8071],\n",
       " [40.0, 0.9654, 0.7811],\n",
       " [39.0, 0.9659, 0.8029],\n",
       " [38.0, 0.9991, 0.7741],\n",
       " [37.0, 0.9992, 0.6571],\n",
       " [36.0, 0.9994, 0.667],\n",
       " [35.0, 0.9992, 0.6312],\n",
       " [34.0, 0.9973, 0.6031],\n",
       " [33.0, 0.9993, 0.6329],\n",
       " [32.0, 0.9948, 0.5877],\n",
       " [31.0, 0.9973, 0.5625],\n",
       " [30.0, 0.995, 0.6215],\n",
       " [29.0, 0.999, 0.5704],\n",
       " [28.0, 0.9995, 0.5677],\n",
       " [27.0, 0.9996, 0.5445],\n",
       " [26.0, 0.9957, 0.5085],\n",
       " [25.0, 0.9995, 0.5387],\n",
       " [24.0, 0.9996, 0.5057],\n",
       " [23.0, 0.9997, 0.525],\n",
       " [22.0, 0.9996, 0.4679],\n",
       " [21.0, 0.9999, 0.4968],\n",
       " [20.0, 0.9988, 0.4621],\n",
       " [19.0, 0.9987, 0.4598],\n",
       " [18.0, 0.9989, 0.4493],\n",
       " [17.0, 0.9986, 0.4633],\n",
       " [16.0, 0.9986, 0.4053],\n",
       " [15.0, 0.9987, 0.4126],\n",
       " [14.0, 0.9987, 0.4261],\n",
       " [13.0, 0.999, 0.3722],\n",
       " [12.0, 0.9989, 0.3606],\n",
       " [11.0, 0.9992, 0.3406],\n",
       " [10.0, 0.9991, 0.3406],\n",
       " [9.0, 0.999, 0.3079],\n",
       " [8.0, 0.9992, 0.3444],\n",
       " [7.0, 0.9992, 0.3257],\n",
       " [6.0, 0.9989, 0.3113],\n",
       " [5.0, 0.9989, 0.2654],\n",
       " [4.0, 0.9988, 0.261],\n",
       " [3.0, 0.9985, 0.2516],\n",
       " [2.0, 0.9994, 0.2527]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smr"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
