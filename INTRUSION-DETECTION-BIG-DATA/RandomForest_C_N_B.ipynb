{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import requests\n",
    "import time\n",
    "\n",
    "from pyspark import SQLContext, SparkContext\n",
    "from pyspark import SparkConf\n",
    "\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
    "from pyspark.ml.linalg import Vectors\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from pyspark.mllib.tree import RandomForest, RandomForestModel\n",
    "from pyspark.mllib.util import MLUtils\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.linalg import Vector as MLLibVector, Vectors as MLLibVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset and labels\n",
    "x=np.load('NBx.npy')\n",
    "y=np.load('NBy.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = SparkConf()\n",
    "sc = SparkContext(conf = conf)\n",
    "spark = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the rank of each feature\n",
    "R=[]\n",
    "for h in range(x.shape[1]):\n",
    "    kmeans = KMeans(init='k-means++', n_clusters=np.unique(y).shape[0])\n",
    "    ff=kmeans.fit_predict(x[:,h].reshape(-1,1))\n",
    "    r=metrics.homogeneity_score(y,ff) #Use the homogeneity score as a rank of the feature\n",
    "    R.append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Arrange feature accroding to thier ranks\n",
    "Rnk=np.argsort(np.array(R))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initiate the cross-validation splitter\n",
    "kfolds=StratifiedKFold(n_splits=5,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Per each set of ranks, use cross-validation to calculate accuracy.\n",
    "smr=[]\n",
    "et=0\n",
    "for j in range(Rnk.shape[0]):\n",
    "    fd=x[:,Rnk[j:]]\n",
    "    pp=0\n",
    "    lpa=np.zeros((0,2))\n",
    "    for train,test in kfolds.split(fd,y):\n",
    "        dff = map(lambda x: (int(float(x[-1])), Vectors.dense(x[:-1])),np.hstack((fd[train],y[train].reshape(-1,1))))\n",
    "        TrD = spark.createDataFrame(dff,schema=[\"label\", \"features\"]).rdd.map(lambda row: LabeledPoint(row.label, MLLibVectors.fromML(row.features)))\n",
    "        dff = map(lambda x: (int(float(x[-1])), Vectors.dense(x[:-1])),np.hstack((fd[test],y[test].reshape(-1,1))))\n",
    "        TsD = spark.createDataFrame(dff,schema=[\"label\", \"features\"]).rdd.map(lambda row: LabeledPoint(row.label, MLLibVectors.fromML(row.features)))\n",
    "        model = RandomForest.trainClassifier(TrD, numClasses=np.unique(y).shape[0],categoricalFeaturesInfo={},numTrees=100) #The number of classes in the dataset\n",
    "        predictions = model.predict(TsD.map(lambda x: x.features))\n",
    "        st = time.time()\n",
    "        labelsAndPredictions = TsD.map(lambda lp: lp.label).zip(predictions)\n",
    "        lpa=np.vstack((lpa,labelsAndPredictions.toDF().toPandas()))\n",
    "        et+=time.time()-st\n",
    "        acc = labelsAndPredictions.filter(lambda lp: lp[0] == lp[1]).count() / float(TsD.count())\n",
    "        pp=pp+acc\n",
    "    pp=pp/kfolds.n_splits\n",
    "    np.savetxt('F%d.csv'%j,lpa,delimiter=',')\n",
    "    smr.append([j, pp, et*1000000/x.shape[0]]) #Calculate the time requires to predict a label per each object in uS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[78.0, 0.9254, 7.685],\n",
       " [77.0, 0.9258, 7.5517],\n",
       " [76.0, 0.9255, 7.7915],\n",
       " [75.0, 0.9254, 7.6001],\n",
       " [74.0, 0.9257, 7.6812],\n",
       " [73.0, 0.9256, 7.6089],\n",
       " [72.0, 0.9255, 7.6214],\n",
       " [71.0, 0.9257, 7.5825],\n",
       " [70.0, 0.9255, 7.5605],\n",
       " [69.0, 0.9254, 7.5314],\n",
       " [68.0, 0.9255, 7.5239],\n",
       " [67.0, 0.9256, 7.4595],\n",
       " [66.0, 0.9256, 7.5068],\n",
       " [65.0, 0.9253, 7.5029],\n",
       " [64.0, 0.9255, 7.5092],\n",
       " [63.0, 0.926, 7.4624],\n",
       " [62.0, 0.9255, 7.4734],\n",
       " [61.0, 0.9253, 7.4213],\n",
       " [60.0, 0.9253, 7.4582],\n",
       " [59.0, 0.9255, 7.562],\n",
       " [58.0, 0.9256, 7.3456],\n",
       " [57.0, 0.9262, 7.3502],\n",
       " [56.0, 0.9257, 7.3494],\n",
       " [55.0, 0.9257, 7.3937],\n",
       " [54.0, 0.9257, 7.31],\n",
       " [53.0, 0.9259, 7.2893],\n",
       " [52.0, 0.9258, 7.2689],\n",
       " [51.0, 0.9255, 7.2481],\n",
       " [50.0, 0.9259, 7.2697],\n",
       " [49.0, 0.9256, 7.2737],\n",
       " [48.0, 0.9257, 7.2836],\n",
       " [47.0, 0.9256, 7.205],\n",
       " [46.0, 0.9258, 7.2247],\n",
       " [45.0, 0.9254, 7.2173],\n",
       " [44.0, 0.9253, 7.1468],\n",
       " [43.0, 0.9256, 7.1579],\n",
       " [42.0, 0.9255, 7.1741],\n",
       " [41.0, 0.9255, 7.1775],\n",
       " [40.0, 0.9256, 7.1734],\n",
       " [39.0, 0.9259, 7.141],\n",
       " [38.0, 0.9248, 7.1096],\n",
       " [37.0, 0.9251, 7.0562],\n",
       " [36.0, 0.9255, 7.0606],\n",
       " [35.0, 0.9255, 7.1374],\n",
       " [34.0, 0.9258, 7.0903],\n",
       " [33.0, 0.9254, 7.0633],\n",
       " [32.0, 0.9252, 7.1158],\n",
       " [31.0, 0.9255, 6.9904],\n",
       " [30.0, 0.9255, 7.062],\n",
       " [29.0, 0.9251, 7.134],\n",
       " [28.0, 0.9255, 7.1321],\n",
       " [27.0, 0.925, 7.0148],\n",
       " [26.0, 0.9248, 7.0662],\n",
       " [25.0, 0.9251, 7.0114],\n",
       " [24.0, 0.9252, 7.0157],\n",
       " [23.0, 0.925, 7.0809],\n",
       " [22.0, 0.9249, 6.9938],\n",
       " [21.0, 0.9252, 6.9523],\n",
       " [20.0, 0.9252, 7.0268],\n",
       " [19.0, 0.9253, 6.9595],\n",
       " [18.0, 0.9253, 6.9834],\n",
       " [17.0, 0.9259, 6.9049],\n",
       " [16.0, 0.9264, 6.9934],\n",
       " [15.0, 0.9267, 7.0474],\n",
       " [14.0, 0.9265, 6.9773],\n",
       " [13.0, 0.9265, 6.9849],\n",
       " [12.0, 0.9268, 6.9787],\n",
       " [11.0, 0.927, 6.9262],\n",
       " [10.0, 0.9269, 6.9206],\n",
       " [9.0, 0.9271, 6.8669],\n",
       " [8.0, 0.927, 6.8345],\n",
       " [7.0, 0.9271, 6.8832],\n",
       " [6.0, 0.9271, 6.8174],\n",
       " [5.0, 0.9271, 6.8599],\n",
       " [4.0, 0.9258, 7.1759],\n",
       " [3.0, 0.9259, 7.1058],\n",
       " [2.0, 0.9023, 6.7687]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smr"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
