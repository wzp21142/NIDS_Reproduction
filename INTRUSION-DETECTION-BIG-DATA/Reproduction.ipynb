{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import GradientBoostingClassifier,RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold,KFold\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder, OneHotEncoder\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.models import Sequential"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def load_data_binary():\n",
    "    # Default values.\n",
    "    train_set = 'data/UNSW_NB15_training-set.csv'\n",
    "    test_set = 'data/UNSW_NB15_testing-set.csv'\n",
    "    train = pd.read_csv(train_set, index_col='id')  # 指定“id”这一列数据作为行索引\n",
    "    test = pd.read_csv(test_set, index_col='id')  # 指定“id”这一列数据作为行索引\n",
    "\n",
    "    # 二分类数据\n",
    "    training_label = train['label']  # 将train的“label”这一列的值单独取出来\n",
    "    testing_label = test['label']  # 将test的“label”这一列的值单独取出来\n",
    "\n",
    "    # Creates new dummy columns from each unique string in a particular feature 创建新的虚拟列\n",
    "    labels = pd.concat([training_label, testing_label])  # 将train和test拼接在一起\n",
    "    unsw = pd.concat([train, test])  # 将train和test拼接在一起\n",
    "    unsw = pd.get_dummies(data=unsw,\n",
    "                          columns=['proto', 'service', 'state'])  # 将'proto', 'service', 'state'这三列使用one-hot-encoder转变\n",
    "    # Normalising all numerical features:\n",
    "    unsw.drop(['label', 'attack_cat'], axis=1,\n",
    "              inplace=True)  # 删除'label', 'attack_cat'这两列，其中(inplace=True)是直接对原dataFrame进行操作\n",
    "    unsw_value = unsw.values\n",
    "\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))  # 初始化MinMaxScaler\n",
    "    unsw_value = scaler.fit_transform(unsw_value)  # 将待处理数据矩阵进行归一化\n",
    "\n",
    "    return unsw_value, labels\n",
    "\n",
    "def load_data_multi():\n",
    "    # Default values.\n",
    "    train_set = 'data/UNSW_NB15_training-set.csv'\n",
    "    test_set = 'data/UNSW_NB15_testing-set.csv'\n",
    "    train = pd.read_csv(train_set, index_col='id')  # 指定“id”这一列数据作为行索引\n",
    "    test = pd.read_csv(test_set, index_col='id')  # 指定“id”这一列数据作为行索引\n",
    "\n",
    "    # 多分类数据\n",
    "    training_label = train['attack_cat']  # 将train的“attack_cat”这一列的值单独取出来\n",
    "    testing_label = test['attack_cat']  # 将test的“attack_cat”这一列的值单独取出来\n",
    "    labels = pd.concat([training_label, testing_label])  # 将train和test拼接在一起\n",
    "    le = LabelEncoder()\n",
    "    le.fit([\"Normal\",\"Generic\",\"Analysis\",\"Reconnaissance\",\"Fuzzers\",\"DoS\",\n",
    "            \"Exploits\",\"Shellcode\",\"Backdoor\",\"Worms\"])\n",
    "    labels = np.array(le.transform(labels)).reshape(-1,1)\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))  # 初始化MinMaxScaler\n",
    "    labels = scaler.fit_transform(labels)  # 将待处理数据矩阵进行归一化\n",
    "    return labels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load data...\n",
      "train shape:  (257673, 196)\n",
      "train_label_binary shape:  (257673, 1)\n",
      "train_label_multi shape:  (257673, 1)\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "print(\"Load data...\")\n",
    "train, train_label_binary = load_data_binary()\n",
    "train_label_multi = load_data_multi()\n",
    "print(\"train shape: \", train.shape)\n",
    "train_label_binary = np.array(train_label_binary).reshape((-1, 1))\n",
    "train_label_multi = np.array(train_label_multi).reshape((-1, 1))\n",
    "print(\"train_label_binary shape: \", train_label_binary.shape)\n",
    "print(\"train_label_multi shape: \", train_label_multi.shape)\n",
    "\n",
    "\n",
    "np.save('data/encoded_train.npy', train)\n",
    "np.save('data/train_label_binary.npy', train_label_binary)\n",
    "np.save('data/train_label_multi.npy', train_label_multi)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load the dataset and labels\n",
    "\n",
    "x = np.load('data/encoded_train.npy')\n",
    "y = np.load('data/train_label_binary.npy')\n",
    "y = y.reshape(y.shape[0])\n",
    "# Calculate the rank of each feature\n",
    "R = []\n",
    "for h in range(x.shape[1]):\n",
    "    kmeans = KMeans(init='k-means++', n_clusters=np.unique(y).shape[0], n_init=10)\n",
    "    ff = kmeans.fit_predict(x[:, h].reshape(-1, 1))\n",
    "    r = metrics.homogeneity_score(y, ff)  # Use the homogeneity score as a rank of the feature\n",
    "    R.append(r)\n",
    "\n",
    "# Arrange feature accroding to thier ranks\n",
    "Rnk = np.argsort(np.array(R))\n",
    "np.save('data/Rnk_binary.npy', Rnk)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Initiate the cross-validation splitter\n",
    "kfolds = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "\n",
    "# Per each set of ranks, use cross-validation to calculate accuracy.\n",
    "smr = []\n",
    "et=0\n",
    "print(x.shape)\n",
    "for j in range(Rnk.shape[0]):\n",
    "    fd = x[:, Rnk[j:]]\n",
    "    pp = 0\n",
    "    lpa = np.zeros((0, 2))\n",
    "    for train, test in kfolds.split(fd, y):\n",
    "        train_t_x = fd[train]\n",
    "        train_t_y = y[train]\n",
    "        test_t_x=fd[test]\n",
    "        test_t_y=y[test]\n",
    "        model = Sequential()\n",
    "        model.add(Dense(units=128, input_dim=fd.shape[1], activation='relu', use_bias=True))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(units=64, activation='relu', use_bias=True))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(units=32, activation='relu', use_bias=True))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(units=1, activation='sigmoid',\n",
    "                        use_bias=True))  # The number of neurons is equal to the number of classes\n",
    "        # model.summary()\n",
    "        model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        history = model.fit(train_t_x,train_t_y, epochs=40, verbose=2,validation_data=(test_t_x,test_t_y))\n",
    "        st = time.time()\n",
    "        ff=model.predict(test_t_x)\n",
    "        et+=time.time()-st\n",
    "        ts = np.array(list(map(lambda x: x[0], ff.reshape(-1, 1))))\n",
    "        pp = pp + metrics.accuracy_score(y[test].reshape(-1, 1), (ts >= 0.5).astype(int))\n",
    "        lpa = np.vstack((lpa, np.hstack((y[test].reshape(-1, 1), ts.reshape(-1, 1)))))\n",
    "\n",
    "    pp = pp / kfolds.n_splits\n",
    "    np.savetxt('F%d_binary.csv' % j, lpa, delimiter=',')\n",
    "    smr.append([j, pp, et*1000000/x.shape[0]]) #Calculate the time required to predict a label per each object in uS."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "#Per each set of ranks, use cross-validation to calculate accuracy.\n",
    "kfolds = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "smr=[]\n",
    "et=0\n",
    "for j in range(Rnk.shape[0]):\n",
    "    fd=x[:,Rnk[j:]]\n",
    "    pp=0\n",
    "    lpa=np.zeros((0,2))\n",
    "    for train,test in kfolds.split(fd,y):\n",
    "        train_t_x = fd[train]\n",
    "        train_t_y = y[train]\n",
    "        test_t_x=fd[test]\n",
    "        test_t_y=y[test]\n",
    "        model = GradientBoostingClassifier()\n",
    "        model.fit(train_t_x,train_t_y)\n",
    "        st = time.time()\n",
    "        predictions = model.predict(test_t_x)\n",
    "        labelsAndPredictions = np.array([test_t_y,predictions])\n",
    "        lpa=np.vstack((lpa,labelsAndPredictions.reshape(-1,2)))\n",
    "        et+=time.time()-st\n",
    "        num=0\n",
    "        si = labelsAndPredictions.shape[1]\n",
    "        label_t = labelsAndPredictions[0]\n",
    "        label_p = labelsAndPredictions[1]\n",
    "        for i in range(si):\n",
    "            if label_t[i] == label_p[i]:\n",
    "                num += 1\n",
    "        acc = num / float(si)\n",
    "        pp=pp+acc\n",
    "    pp=pp/kfolds.n_splits\n",
    "    np.savetxt('F%d_GBT_B.csv'%j,lpa,delimiter=',')\n",
    "    smr.append([j, pp, et*1000000/x.shape[0]]) #Calculate the time required to predict a label per each object in uS."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9504026389832153\n",
      "0.9501115746579994\n",
      "0.9496846803143495\n",
      "0.9505375092172158\n",
      "0.9526138083595296\n"
     ]
    }
   ],
   "source": [
    "#Initiate the cross-validation splitter\n",
    "kfolds=StratifiedKFold(n_splits=5,shuffle=True)\n",
    "#Per each set of ranks, use cross-validation to calculate accuracy.\n",
    "smr=[]\n",
    "et=0\n",
    "for j in range(Rnk.shape[0]):\n",
    "    fd=x[:,Rnk[j:]]\n",
    "    pp=0\n",
    "    lpa=np.zeros((0,2))\n",
    "    for train,test in kfolds.split(fd,y):\n",
    "        train_t_x = fd[train]\n",
    "        train_t_y = y[train]\n",
    "        test_t_x=fd[test]\n",
    "        test_t_y=y[test]\n",
    "        model = RandomForestClassifier(n_estimators=100) #The number of classes in the dataset\n",
    "        model.n_outputs_=np.unique(y).shape[0]\n",
    "        model.fit(train_t_x,train_t_y)\n",
    "        st = time.time()\n",
    "        predictions = model.predict(test_t_x)\n",
    "        labelsAndPredictions = np.array([test_t_y,predictions])\n",
    "        lpa=np.vstack((lpa,labelsAndPredictions.reshape(-1,2)))\n",
    "        et+=time.time()-st\n",
    "        num=0\n",
    "        si = labelsAndPredictions.shape[1]\n",
    "        label_t = labelsAndPredictions[0]\n",
    "        label_p = labelsAndPredictions[1]\n",
    "        for i in range(si):\n",
    "            if label_t[i] == label_p[i]:\n",
    "                num += 1\n",
    "        acc = num / float(si)\n",
    "        print(acc)\n",
    "        pp=pp+acc\n",
    "    pp=pp/kfolds.n_splits\n",
    "    np.savetxt('F%d_RF_B.csv'%j,lpa,delimiter=',')\n",
    "    smr.append([j, pp, et*1000000/x.shape[0]]) #Calculate the time required to predict a label per each object in uS."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (9) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (7) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1122: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return self.fit(X, sample_weight=sample_weight).labels_\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset and labels\n",
    "\n",
    "x = np.load('data/encoded_train.npy')\n",
    "y = np.load('data/train_label_multi.npy')\n",
    "y=y.reshape(y.shape[0])\n",
    "# Calculate the rank of each feature\n",
    "R = []\n",
    "for h in range(x.shape[1]):\n",
    "    kmeans = KMeans(init='k-means++', n_clusters=np.unique(y).shape[0], n_init=10)\n",
    "    ff = kmeans.fit_predict(x[:, h].reshape(-1, 1))\n",
    "    r = metrics.homogeneity_score(y, ff)  # Use the homogeneity score as a rank of the feature\n",
    "    R.append(r)\n",
    "# Arrange feature accroding to thier ranks\n",
    "Rnk = np.argsort(np.array(R))\n",
    "np.save('data/Rnk_multi.npy', Rnk)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(257673, 196)\n",
      "Processing feature # 1\n",
      "Processing fold # 1\n",
      "6442/6442 - 18s - loss: 0.7521 - categorical_accuracy: 0.7186 - val_loss: 0.5973 - val_categorical_accuracy: 0.7603\n",
      "0.9558144950033958\n",
      "Processing fold # 2\n",
      "6442/6442 - 17s - loss: 0.7552 - categorical_accuracy: 0.7164 - val_loss: 0.5932 - val_categorical_accuracy: 0.7575\n",
      "1.9113476278257495\n",
      "Processing fold # 3\n",
      "6442/6442 - 18s - loss: 0.7624 - categorical_accuracy: 0.7147 - val_loss: 0.6032 - val_categorical_accuracy: 0.7588\n",
      "2.866550887746192\n",
      "Processing fold # 4\n",
      "6442/6442 - 18s - loss: 0.7572 - categorical_accuracy: 0.7184 - val_loss: 0.6005 - val_categorical_accuracy: 0.7597\n",
      "3.8213787683686933\n",
      "Processing fold # 5\n",
      "6442/6442 - 18s - loss: 0.7552 - categorical_accuracy: 0.7168 - val_loss: 0.6116 - val_categorical_accuracy: 0.7587\n",
      "4.77506177376319\n",
      "Processing feature # 2\n",
      "Processing fold # 1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-13-092e3d1ac5f0>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     35\u001B[0m         \u001B[1;31m#model.summary()\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     36\u001B[0m         \u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcompile\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mloss\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m'categorical_crossentropy'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0moptimizer\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m'adam'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmetrics\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'categorical_accuracy'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 37\u001B[1;33m         \u001B[0mhistory\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtrain_t_x\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mtrain_t_y\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mepochs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mverbose\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m2\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mvalidation_data\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtest_t_x\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mtest_t_y\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     38\u001B[0m         \u001B[0mst\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtime\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtime\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     39\u001B[0m         \u001B[0mff\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtest_t_x\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001B[0m in \u001B[0;36m_method_wrapper\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    106\u001B[0m   \u001B[1;32mdef\u001B[0m \u001B[0m_method_wrapper\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    107\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_in_multi_worker_mode\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m  \u001B[1;31m# pylint: disable=protected-access\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 108\u001B[1;33m       \u001B[1;32mreturn\u001B[0m \u001B[0mmethod\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    109\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    110\u001B[0m     \u001B[1;31m# Running inside `run_distribute_coordinator` already.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[0;32m   1096\u001B[0m                 batch_size=batch_size):\n\u001B[0;32m   1097\u001B[0m               \u001B[0mcallbacks\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mon_train_batch_begin\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mstep\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1098\u001B[1;33m               \u001B[0mtmp_logs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtrain_function\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0miterator\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1099\u001B[0m               \u001B[1;32mif\u001B[0m \u001B[0mdata_handler\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshould_sync\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1100\u001B[0m                 \u001B[0mcontext\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0masync_wait\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    778\u001B[0m       \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    779\u001B[0m         \u001B[0mcompiler\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;34m\"nonXla\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 780\u001B[1;33m         \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    781\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    782\u001B[0m       \u001B[0mnew_tracing_count\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_get_tracing_count\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001B[0m in \u001B[0;36m_call\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    805\u001B[0m       \u001B[1;31m# In this case we have created variables on the first call, so we run the\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    806\u001B[0m       \u001B[1;31m# defunned version which is guaranteed to never create variables.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 807\u001B[1;33m       \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_stateless_fn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# pylint: disable=not-callable\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    808\u001B[0m     \u001B[1;32melif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_stateful_fn\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    809\u001B[0m       \u001B[1;31m# Release the lock early so that multiple threads can perform the call\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   2827\u001B[0m     \u001B[1;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_lock\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2828\u001B[0m       \u001B[0mgraph_function\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkwargs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_maybe_define_function\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 2829\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0mgraph_function\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_filtered_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# pylint: disable=protected-access\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   2830\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2831\u001B[0m   \u001B[1;33m@\u001B[0m\u001B[0mproperty\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001B[0m in \u001B[0;36m_filtered_call\u001B[1;34m(self, args, kwargs, cancellation_manager)\u001B[0m\n\u001B[0;32m   1841\u001B[0m       \u001B[0;31m`\u001B[0m\u001B[0margs\u001B[0m\u001B[0;31m`\u001B[0m \u001B[1;32mand\u001B[0m\u001B[0;31m \u001B[0m\u001B[0;31m`\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;31m`\u001B[0m\u001B[1;33m.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1842\u001B[0m     \"\"\"\n\u001B[1;32m-> 1843\u001B[1;33m     return self._call_flat(\n\u001B[0m\u001B[0;32m   1844\u001B[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001B[0;32m   1845\u001B[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001B[1;32mD:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001B[0m in \u001B[0;36m_call_flat\u001B[1;34m(self, args, captured_inputs, cancellation_manager)\u001B[0m\n\u001B[0;32m   1921\u001B[0m         and executing_eagerly):\n\u001B[0;32m   1922\u001B[0m       \u001B[1;31m# No tape is watching; skip to running the function.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1923\u001B[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001B[0m\u001B[0;32m   1924\u001B[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001B[0;32m   1925\u001B[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001B[1;32mD:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001B[0m in \u001B[0;36mcall\u001B[1;34m(self, ctx, args, cancellation_manager)\u001B[0m\n\u001B[0;32m    543\u001B[0m       \u001B[1;32mwith\u001B[0m \u001B[0m_InterpolateFunctionError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    544\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mcancellation_manager\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 545\u001B[1;33m           outputs = execute.execute(\n\u001B[0m\u001B[0;32m    546\u001B[0m               \u001B[0mstr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msignature\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    547\u001B[0m               \u001B[0mnum_outputs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_num_outputs\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001B[0m in \u001B[0;36mquick_execute\u001B[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[0;32m     57\u001B[0m   \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     58\u001B[0m     \u001B[0mctx\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mensure_initialized\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 59\u001B[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001B[0m\u001B[0;32m     60\u001B[0m                                         inputs, attrs, num_outputs)\n\u001B[0;32m     61\u001B[0m   \u001B[1;32mexcept\u001B[0m \u001B[0mcore\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_NotOkStatusException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "x = np.load('data/encoded_train.npy')\n",
    "y = np.load('data/train_label_multi.npy')\n",
    "y = OneHotEncoder(sparse=False).fit_transform(y.reshape(-1,1))\n",
    "\n",
    "Rnk=np.load('data/Rnk_multi.npy')\n",
    "# Initiate the cross-validation splitter\n",
    "kfolds = KFold(n_splits=5, shuffle=True)\n",
    "et=0\n",
    "# Per each set of ranks, use cross-validation to calculate accuracy.\n",
    "smr = []\n",
    "print(x.shape)\n",
    "features_count=1\n",
    "for j in range(Rnk.shape[0]):\n",
    "    print('Processing feature #',features_count)\n",
    "    features_count+=1\n",
    "    fd = x[:, Rnk[j:]]\n",
    "    pp = 0\n",
    "    lpa = np.zeros((0, 2))\n",
    "    fold=1\n",
    "    for train, test in kfolds.split(fd, y):\n",
    "        print('Processing fold #',fold)\n",
    "        fold+=1\n",
    "        train_t_x = fd[train]\n",
    "        train_t_y = y[train]\n",
    "        test_t_x=fd[test]\n",
    "        test_t_y=y[test]\n",
    "        model = Sequential()\n",
    "        model.add(Dense(units=128, input_dim=fd.shape[1], activation='relu', use_bias=True))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(units=64, activation='relu', use_bias=True))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(units=32, activation='relu', use_bias=True))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(10,activation='softmax',use_bias=True)) #The number of neurons is equal to the number of classes\n",
    "        #model.summary()\n",
    "        model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])\n",
    "        history = model.fit(train_t_x,train_t_y, epochs=1, verbose=2,validation_data=(test_t_x,test_t_y))\n",
    "        st = time.time()\n",
    "        ff=model.predict(test_t_x)\n",
    "        et+=time.time()-st\n",
    "        ts = np.array(list(map(lambda x: x[0], ff.reshape(-1, 1))))\n",
    "        pp = pp + metrics.accuracy_score(y[test].reshape(-1, 1), (ts >= 0.5).astype(int))\n",
    "        lpa = np.vstack((lpa, np.hstack((y[test].reshape(-1, 1), ts.reshape(-1, 1)))))\n",
    "    pp = pp / kfolds.n_splits\n",
    "    np.savetxt('F%d_multi.csv' % j, lpa, delimiter=',')\n",
    "    smr.append([j, pp, et*1000000/x.shape[0]]) #Calculate\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(257673, 196)\n",
      "Processing feature # 1\n",
      "Processing fold # 1\n",
      "0.7663335597166974\n",
      "Processing fold # 2\n",
      "0.771786164742408\n",
      "Processing fold # 3\n",
      "0.769108372950422\n",
      "Processing fold # 4\n",
      "0.7705786471067645\n",
      "Processing fold # 5\n",
      "0.7692009159001824\n",
      "Processing feature # 2\n",
      "Processing fold # 1\n",
      "0.769671097312506\n",
      "Processing fold # 2\n",
      "0.7676336470359949\n",
      "Processing fold # 3\n",
      "0.7659842825264384\n",
      "Processing fold # 4\n",
      "0.7704816237823573\n",
      "Processing fold # 5\n",
      "0.7680172313424147\n",
      "Processing feature # 3\n",
      "Processing fold # 1\n",
      "0.7652275152808771\n",
      "Processing fold # 2\n",
      "0.7711846318036286\n",
      "Processing fold # 3\n",
      "0.76699330552052\n",
      "Processing fold # 4\n",
      "0.7658827182054566\n",
      "Processing fold # 5\n",
      "0.7686187759537393\n",
      "Processing feature # 4\n",
      "Processing fold # 1\n",
      "0.7709711846318036\n",
      "Processing fold # 2\n",
      "0.769108372950422\n",
      "Processing fold # 3\n",
      "0.7640244494033182\n",
      "Processing fold # 4\n",
      "0.7705204331121202\n",
      "Processing fold # 5\n",
      "0.7657468855512866\n",
      "Processing feature # 5\n",
      "Processing fold # 1\n",
      "0.7684292228582517\n",
      "Processing fold # 2\n",
      "0.7662559425633065\n",
      "Processing fold # 3\n",
      "0.7657514310662656\n",
      "Processing fold # 4\n",
      "0.7687352039430279\n",
      "Processing fold # 5\n",
      "0.7693755578841154\n",
      "Processing feature # 6\n",
      "Processing fold # 1\n",
      "0.7705442902881536\n",
      "Processing fold # 2\n",
      "0.7675560298826041\n",
      "Processing fold # 3\n",
      "0.7672455612690404\n",
      "Processing fold # 4\n",
      "0.7698606745061513\n",
      "Processing fold # 5\n",
      "0.7698994838359141\n",
      "Processing feature # 7\n",
      "Processing fold # 1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-16-702c53c37a43>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     28\u001B[0m         \u001B[0mmodel\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mRandomForestClassifier\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mn_estimators\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m100\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;31m#The number of classes in the dataset\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     29\u001B[0m         \u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mn_outputs_\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m10\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 30\u001B[1;33m         \u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtrain_t_x\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mtrain_t_y\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     31\u001B[0m         \u001B[0mst\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtime\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtime\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     32\u001B[0m         \u001B[0mpredictions\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtest_t_x\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[0;32m    384\u001B[0m             \u001B[1;31m# parallel_backend contexts set at a higher level,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    385\u001B[0m             \u001B[1;31m# since correctness does not rely on using threads.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 386\u001B[1;33m             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n\u001B[0m\u001B[0;32m    387\u001B[0m                              \u001B[1;33m**\u001B[0m\u001B[0m_joblib_parallel_args\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mprefer\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m'threads'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    388\u001B[0m                 delayed(_parallel_build_trees)(\n",
      "\u001B[1;32mD:\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m   1049\u001B[0m                 \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_iterating\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_original_iterator\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1050\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1051\u001B[1;33m             \u001B[1;32mwhile\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdispatch_one_batch\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0miterator\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1052\u001B[0m                 \u001B[1;32mpass\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1053\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001B[0m in \u001B[0;36mdispatch_one_batch\u001B[1;34m(self, iterator)\u001B[0m\n\u001B[0;32m    864\u001B[0m                 \u001B[1;32mreturn\u001B[0m \u001B[1;32mFalse\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    865\u001B[0m             \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 866\u001B[1;33m                 \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_dispatch\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtasks\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    867\u001B[0m                 \u001B[1;32mreturn\u001B[0m \u001B[1;32mTrue\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    868\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001B[0m in \u001B[0;36m_dispatch\u001B[1;34m(self, batch)\u001B[0m\n\u001B[0;32m    782\u001B[0m         \u001B[1;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_lock\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    783\u001B[0m             \u001B[0mjob_idx\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_jobs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 784\u001B[1;33m             \u001B[0mjob\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_backend\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mapply_async\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mbatch\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcallback\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mcb\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    785\u001B[0m             \u001B[1;31m# A job can complete so quickly than its callback is\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    786\u001B[0m             \u001B[1;31m# called before we get here, causing self._jobs to\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001B[0m in \u001B[0;36mapply_async\u001B[1;34m(self, func, callback)\u001B[0m\n\u001B[0;32m    206\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mapply_async\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfunc\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcallback\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    207\u001B[0m         \u001B[1;34m\"\"\"Schedule a func to be run\"\"\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 208\u001B[1;33m         \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mImmediateResult\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfunc\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    209\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mcallback\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    210\u001B[0m             \u001B[0mcallback\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mresult\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, batch)\u001B[0m\n\u001B[0;32m    570\u001B[0m         \u001B[1;31m# Don't delay the application, to avoid keeping the input\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    571\u001B[0m         \u001B[1;31m# arguments in memory\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 572\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mresults\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mbatch\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    573\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    574\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mget\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    260\u001B[0m         \u001B[1;31m# change the default number of processes to -1\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    261\u001B[0m         \u001B[1;32mwith\u001B[0m \u001B[0mparallel_backend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_backend\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mn_jobs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_n_jobs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 262\u001B[1;33m             return [func(*args, **kwargs)\n\u001B[0m\u001B[0;32m    263\u001B[0m                     for func, args, kwargs in self.items]\n\u001B[0;32m    264\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001B[0m in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    260\u001B[0m         \u001B[1;31m# change the default number of processes to -1\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    261\u001B[0m         \u001B[1;32mwith\u001B[0m \u001B[0mparallel_backend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_backend\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mn_jobs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_n_jobs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 262\u001B[1;33m             return [func(*args, **kwargs)\n\u001B[0m\u001B[0;32m    263\u001B[0m                     for func, args, kwargs in self.items]\n\u001B[0;32m    264\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001B[0m in \u001B[0;36m_parallel_build_trees\u001B[1;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001B[0m\n\u001B[0;32m    166\u001B[0m                                                         indices=indices)\n\u001B[0;32m    167\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 168\u001B[1;33m         \u001B[0mtree\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msample_weight\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mcurr_sample_weight\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcheck_input\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mFalse\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    169\u001B[0m     \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    170\u001B[0m         \u001B[0mtree\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msample_weight\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0msample_weight\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcheck_input\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mFalse\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001B[0m\n\u001B[0;32m    888\u001B[0m         \"\"\"\n\u001B[0;32m    889\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 890\u001B[1;33m         super().fit(\n\u001B[0m\u001B[0;32m    891\u001B[0m             \u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    892\u001B[0m             \u001B[0msample_weight\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0msample_weight\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001B[0m\n\u001B[0;32m    373\u001B[0m                                            min_impurity_split)\n\u001B[0;32m    374\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 375\u001B[1;33m         \u001B[0mbuilder\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbuild\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtree_\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msample_weight\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mX_idx_sorted\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    376\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    377\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mn_outputs_\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;36m1\u001B[0m \u001B[1;32mand\u001B[0m \u001B[0mis_classifier\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "x = np.load('data/encoded_train.npy')\n",
    "y = np.load('data/train_label_multi.npy')\n",
    "y = OneHotEncoder(sparse=False).fit_transform(y.reshape(-1,1))\n",
    "\n",
    "Rnk=np.load('data/Rnk_multi.npy')\n",
    "#Initiate the cross-validation splitter\n",
    "kfolds=KFold(n_splits=5,shuffle=True)\n",
    "\n",
    "#Per each set of ranks, use cross-validation to calculate accuracy.\n",
    "smr=[]\n",
    "et=0\n",
    "print(x.shape)\n",
    "features_count=1\n",
    "for j in range(Rnk.shape[0]):\n",
    "    print('Processing feature #',features_count)\n",
    "    features_count+=1\n",
    "    fd=x[:,Rnk[j:]]\n",
    "    pp=0\n",
    "    lpa=np.zeros((0,2))\n",
    "    fold=1\n",
    "    for train, test in kfolds.split(fd, y):\n",
    "        print('Processing fold #',fold)\n",
    "        fold+=1\n",
    "        train_t_x = fd[train]\n",
    "        train_t_y = y[train]\n",
    "        test_t_x=fd[test]\n",
    "        test_t_y=y[test]\n",
    "        model = RandomForestClassifier(n_estimators=100) #The number of classes in the dataset\n",
    "        model.n_outputs_=10\n",
    "        model.fit(train_t_x,train_t_y)\n",
    "        st = time.time()\n",
    "        predictions = model.predict(test_t_x)\n",
    "        labelsAndPredictions = np.array([test_t_y,predictions])\n",
    "        lpa=np.vstack((lpa,labelsAndPredictions.reshape(-1,2)))\n",
    "        et+=time.time()-st\n",
    "        num=0\n",
    "        si = labelsAndPredictions.shape[1]\n",
    "        label_t = labelsAndPredictions[0]\n",
    "        label_p = labelsAndPredictions[1]\n",
    "        for i in range(si):\n",
    "            if np.array_equal(label_t[i],label_p[i]):\n",
    "                num += 1\n",
    "        acc = num / float(si)\n",
    "        print(acc)\n",
    "        pp=pp+acc\n",
    "    pp=pp/kfolds.n_splits\n",
    "    np.savetxt('F%d_RF_B.csv'%j,lpa,delimiter=',')\n",
    "    smr.append([j, pp, et*1000000/x.shape[0]]) #Calculate the time required to predict a label per each object in uS."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-8bba76b",
   "language": "python",
   "display_name": "PyCharm (SGM-CNN)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}