{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras import callbacks\n",
    "from keras.layers import Dense,Dropout,BatchNormalization,Convolution1D, MaxPooling1D, Flatten,LSTM\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, CSVLogger\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import Normalizer, OneHotEncoder, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score,roc_curve,auc,f1_score\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from sklearn.metrics import precision_score,recall_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "from art.attacks.evasion import FastGradientMethod, SaliencyMapMethod, BasicIterativeMethod\n",
    "from art.classifiers import KerasClassifier\n",
    "\n",
    "import matplotlib\n",
    "#matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "#plt.style.use('bmh')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "names=['duration','protocol_type','service','flag','src_bytes','dst_bytes','land',\n",
    "       'wrong_fragment','urgent','hot','num_failed_logins','logged_in','num_compromised',\n",
    "       'root_shell','su_attempted','num_root','num_file_creations','num_shells',\n",
    "       'num_access_files','num_outbound_cmds','is_host_login','is_guest_login',\n",
    "       'count','srv_count','serror_rate','srv_serror_rate','rerror_rate','srv_rerror_rate'\n",
    "       ,'same_srv_rate','diff_srv_rate','srv_diff_host_rate','dst_host_count',\n",
    "       'dst_host_srv_count','dst_host_same_srv_rate','dst_host_diff_srv_rate',\n",
    "       'dst_host_same_src_port_rate','dst_host_srv_diff_host_rate','dst_host_serror_rate',\n",
    "       'dst_host_srv_serror_rate','dst_host_rerror_rate','dst_host_srv_rerror_rate',\n",
    "       'connection_type','label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Train and Test DF :  (125973, 43)  :  (22544, 43)\n"
     ]
    }
   ],
   "source": [
    "traindata = pd.read_csv('KDDTrain+.txt',names=names,header=None)\n",
    "testdata = pd.read_csv('KDDTest+.txt',names=names, header=None)\n",
    "print(\"Shape of Train and Test DF : \",traindata.shape,\" : \",testdata.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Train and Test :  (125973, 41)  :  (22544, 41)\n"
     ]
    }
   ],
   "source": [
    "x_train = np.array(traindata.iloc[:,0:41])\n",
    "x_test = np.array(testdata.iloc[:,0:41])\n",
    "\n",
    "y_train =  np.array(traindata.iloc[:,42])\n",
    "y_test = np.array(testdata.iloc[:,42])\n",
    "\n",
    "print(\"Shape of Train and Test : \",x_train.shape,\" : \",x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preOEC(data):\n",
    "    label_encoder = LabelEncoder()\n",
    "    for i in range(3):\n",
    "        data[:,i+1] = label_encoder.fit_transform(data[:,i+1])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "x_train=preOEC(x_train)\n",
    "x_test=preOEC(x_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "scaler = Normalizer().fit(x_train)\n",
    "x_train = scaler.transform(x_train)\n",
    "x_test = scaler.transform(x_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_oh= to_categorical(y_train)\n",
    "y_test_oh= to_categorical(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Train and Test :  (125973, 41)  :  (22544, 41)\n"
     ]
    }
   ],
   "source": [
    "x_train_lstm = np.reshape(x_train, (x_train.shape[0],1,x_train.shape[1]))\n",
    "x_test_lstm = np.reshape(x_test, (x_test.shape[0],1,x_test.shape[1]))\n",
    "print(\"Shape of Train and Test : \",x_train.shape,\" : \",x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Train and Test :  (125973, 41)  :  (22544, 41)\n"
     ]
    }
   ],
   "source": [
    "x_train_cnn = np.reshape(x_train, (x_train.shape[0],x_train.shape[1],1))\n",
    "x_test_cnn = np.reshape(x_test, (x_test.shape[0],x_test.shape[1],1))\n",
    "print(\"Shape of Train and Test : \",x_train.shape,\" : \",x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printMetrics(true,pred):\n",
    "    print(\"Accuracy : \",accuracy_score(true, pred))\n",
    "    print(\"Precision\",precision_score(true, pred , average=\"weighted\"))\n",
    "    print(\"Recall : \",recall_score(true, pred , average=\"weighted\"))\n",
    "    print(\"F1-score : \",f1_score(true, pred, average=\"weighted\"))\n",
    "    print(\"Confusion Matrix : \")\n",
    "    print(confusion_matrix(true, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adversarialFeatures(actual,adversarial,data):\n",
    "    feats=dict()\n",
    "    total=0\n",
    "    orig_attack=actual - adversarial\n",
    "    for i in range(0,orig_attack.shape [0]) :\n",
    "        ind=np.where(orig_attack [i,:] != 0) [0]\n",
    "        total += len(ind)\n",
    "        for j in ind :\n",
    "            if j in feats :\n",
    "                feats [j] += 1\n",
    "            else :\n",
    "                feats [j]=1\n",
    "                \n",
    "    # The number of features that where changed for the adversarial samples\n",
    "    print(\" Number of unique features changed :\",len(feats.keys()))\n",
    "    print(\" Number of average features changed per datapoint \",total / len(orig_attack))\n",
    "\n",
    "    top_10=sorted(feats,key=feats.get,reverse=True) [:10]\n",
    "    top_20=sorted(feats,key=feats.get,reverse=True) [:20]\n",
    "\n",
    "\n",
    "    print(\" Top ten features :\",data.columns [ top_10 ])\n",
    "\n",
    "    top_10_val=[100* feats [k ] / y_test.shape [0] for k in top_10 ]\n",
    "    top_20_val=[100* feats [k ] / y_test.shape [0] for k in top_20 ]\n",
    "\n",
    "\n",
    "    plt.bar(np.arange(20),top_20_val,align ='center')\n",
    "    plt.xticks(np.arange(20),data.columns [ top_20 ],rotation ='vertical')\n",
    "    plt.title('Feature participation in adversarial examples')\n",
    "    plt.ylabel('Percentage(%)')\n",
    "    plt.xlabel('Features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 1024)              43008     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 768)               787200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 768)               3072      \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 512)               393728    \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 1,399,557\n",
      "Trainable params: 1,394,181\n",
      "Non-trainable params: 5,376\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dnnmodel = Sequential()\n",
    "dnnmodel.add(Dense(1024,input_dim=41,activation='relu'))\n",
    "dnnmodel.add(BatchNormalization())\n",
    "dnnmodel.add(Dropout(0.01))\n",
    "dnnmodel.add(Dense(768,activation='relu'))\n",
    "dnnmodel.add(BatchNormalization())\n",
    "dnnmodel.add(Dropout(0.01))\n",
    "dnnmodel.add(Dense(512,activation='relu')) \n",
    "dnnmodel.add(BatchNormalization())\n",
    "dnnmodel.add(Dropout(0.01))\n",
    "dnnmodel.add(Dense(256,activation='relu'))\n",
    "dnnmodel.add(BatchNormalization())\n",
    "dnnmodel.add(Dropout(0.01))\n",
    "dnnmodel.add(Dense(128,activation='relu')) \n",
    "dnnmodel.add(BatchNormalization())\n",
    "dnnmodel.add(Dropout(0.01))\n",
    "dnnmodel.add(Dense(5,activation='softmax'))\n",
    "dnnmodel.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "dnnmodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\envs\\tf1\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(64, 3, activation=\"relu\", input_shape=(41, 1), padding=\"same\")`\n",
      "  \n",
      "d:\\anaconda3\\envs\\tf1\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(64, 3, activation=\"relu\", padding=\"same\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "d:\\anaconda3\\envs\\tf1\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `MaxPooling1D` call to the Keras 2 API: `MaxPooling1D(pool_size=2)`\n",
      "  after removing the cwd from sys.path.\n",
      "d:\\anaconda3\\envs\\tf1\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(128, 3, activation=\"relu\", padding=\"same\")`\n",
      "  \"\"\"\n",
      "d:\\anaconda3\\envs\\tf1\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(128, 3, activation=\"relu\", padding=\"same\")`\n",
      "  \n",
      "d:\\anaconda3\\envs\\tf1\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `MaxPooling1D` call to the Keras 2 API: `MaxPooling1D(pool_size=2)`\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_5 (Conv1D)            (None, 41, 64)            256       \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 41, 64)            12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 20, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 20, 128)           24704     \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 20, 128)           49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 10, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 128)               163968    \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 251,205\n",
      "Trainable params: 251,205\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnnmodel = Sequential()\n",
    "cnnmodel.add(Convolution1D(64, 3, border_mode=\"same\",activation=\"relu\",input_shape=(41, 1)))\n",
    "cnnmodel.add(Convolution1D(64, 3, border_mode=\"same\", activation=\"relu\"))\n",
    "cnnmodel.add(MaxPooling1D(pool_length=(2)))\n",
    "cnnmodel.add(Convolution1D(128, 3, border_mode=\"same\", activation=\"relu\"))\n",
    "cnnmodel.add(Convolution1D(128, 3, border_mode=\"same\", activation=\"relu\"))\n",
    "cnnmodel.add(MaxPooling1D(pool_length=(2)))\n",
    "cnnmodel.add(Flatten())\n",
    "cnnmodel.add(Dense(128, activation=\"relu\"))\n",
    "cnnmodel.add(Dropout(0.5))\n",
    "cnnmodel.add(Dense(5, activation=\"softmax\"))\n",
    "cnnmodel.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "cnnmodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\envs\\tf1\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "  \n",
      "d:\\anaconda3\\envs\\tf1\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(64, return_sequences=True, input_shape=(None, 41))`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_5 (LSTM)                (None, None, 64)          27136     \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, None, 64)          0         \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, None, 64)          33024     \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, None, 64)          0         \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, None, 64)          33024     \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, None, 64)          0         \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 5)                 325       \n",
      "=================================================================\n",
      "Total params: 126,533\n",
      "Trainable params: 126,533\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lstmmodel = Sequential()\n",
    "lstmmodel.add(LSTM(64,input_dim=41, return_sequences=True))  # try using a GRU instead, for fun\n",
    "lstmmodel.add(Dropout(0.1))\n",
    "lstmmodel.add(LSTM(64,return_sequences=True))  # try using a GRU instead, for fun\n",
    "lstmmodel.add(Dropout(0.1))\n",
    "lstmmodel.add(LSTM(64, return_sequences=True))  # try using a GRU instead, for fun\n",
    "lstmmodel.add(Dropout(0.1))\n",
    "lstmmodel.add(LSTM(64, return_sequences=False))  # try using a GRU instead, for fun\n",
    "lstmmodel.add(Dropout(0.1))\n",
    "lstmmodel.add(Dense(5,activation='softmax'))\n",
    "lstmmodel.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "lstmmodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "\"dnnmodel.load_weights('Colab_run/results/DNN/checkpoint-80.hdf5')\\ncnnmodel.load_weights('Colab_run/results/CNN/checkpoint-54.hdf5')\\nlstmmodel.load_weights('Colab_run/results/LSTM/checkpoint-10.hdf5')\\n\""
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''dnnmodel.load_weights('Colab_run/results/DNN/checkpoint-80.hdf5')\n",
    "cnnmodel.load_weights('Colab_run/results/CNN/checkpoint-54.hdf5')\n",
    "lstmmodel.load_weights('Colab_run/results/LSTM/checkpoint-10.hdf5')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22544/22544 [==============================] - 5s 236us/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Accuracy :  0.0042583392476933995\n",
      "Precision 6.333753778929773e-05\n",
      "Recall :  0.0042583392476933995\n",
      "F1-score :  0.00011787731374889138\n",
      "Confusion Matrix : \n",
      "[[   0   39   77    0    7    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [   0   26   48    0   13    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [   0   15   35    0    5    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [   0   20   46    1   49    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [   0   25   39    3   34    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [   0   30   39    8   26    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [   0   20   96   11   30    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [   0   46  167    8   28    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [   0   14  100    2   15    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [   0   18   66    4   18    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [   0   29  140    1   25    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [   0  108  298    3   52    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [   0  137  301    9   39    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [   0  109  217    1  192    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [   0   83  474    4  175    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [   0   74  917    0  185    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [   0   18  551    4  108    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [   0   23  977    8  160    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [   0  119 1924  209  715    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [   0   12  440    5  433    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [   0   84  584   28  647    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [   0 5887 1502   35 3270    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\envs\\tf1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "dnnPred = dnnmodel.predict_classes(x_test,verbose=1)\n",
    "printMetrics(y_test,dnnPred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22544/22544 [==============================] - 3s 117us/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Accuracy :  0.003992193044712562\n",
      "Precision 3.978311829705014e-05\n",
      "Recall :  0.003992193044712562\n",
      "F1-score :  7.878087200675527e-05\n",
      "Confusion Matrix : \n",
      "[[  55    0    0    0   68    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [  48    0    0    0   39    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [  31    0    0    0   24    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [  70    0    0    0   46    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [  66    0    0    0   35    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [  61    0    0    0   42    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [  95    0    0    0   62    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [ 159    0    0    0   90    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [  67    0    0    0   64    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [  78    0    0    0   28    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [ 130    0    0    0   65    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [ 172    0    0    0  289    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [ 192    0    0    0  294    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [ 356    0    0    0  163    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [ 385    0    0    0  351    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [ 736    0    0    0  440    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [ 463    0    0    0  218    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [1000    0    1    0  167    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [2278    0    0    0  689    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [ 779    0    0    0  111    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [1049    0    0    0  294    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [3884    0    0    0 6810    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "cnnPred = cnnmodel.predict_classes(x_test_cnn,verbose=1)\n",
    "printMetrics(y_test,cnnPred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22544/22544 [==============================] - 2s 109us/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Accuracy :  0.002528388928317956\n",
      "Precision 2.0052034870285977e-05\n",
      "Recall :  0.002528388928317956\n",
      "F1-score :  3.904603706477196e-05\n",
      "Confusion Matrix : \n",
      "[[  10    6  102    5    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [  14    0   70    3    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [   8    0   46    1    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [  54    0   61    1    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [  46    0   54    1    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [  36    1   66    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [  46    0  110    1    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [  55   13  181    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [  31   38   61    1    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [  57    0   48    1    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [  83    2  110    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [  91    2  368    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [ 144   19  320    3    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [ 306    2  210    1    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [ 334   45  351    6    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [ 438   13  722    3    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [ 352   13  314    2    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [ 564   61  542    1    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [1751  266  929   21    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [ 655   10  221    4    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [ 951   10  347   35    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [3434    4 6193 1063    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "lstmPred = lstmmodel.predict_classes(x_test_lstm,verbose=1)\n",
    "printMetrics(y_test,lstmPred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = KerasClassifier(clip_values=(np.min(x_train), np.max(x_train)), model=dnnmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "fgsm = FastGradientMethod(classifier, \n",
    "                          eps=.01,\n",
    "                          minimal=True,\n",
    "                          eps_step=0.01,\n",
    "                          num_random_init=35,\n",
    "                          targeted=False,\n",
    "                          batch_size=32)\n",
    "\n",
    "x_test_adv_fgsm = fgsm.generate(x=x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "JSMA:   0%|          | 0/705 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7e33d8c000304ac9aa94d5c79d3076b1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "jsma=SaliencyMapMethod(classifier,batch_size=32)\n",
    "x_test_adv_jsma=jsma.generate(x=x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Number of unique features changed : 41\n",
      " Number of average features changed per datapoint  26.550212916962384\n",
      " Top ten features : Index(['service', 'flag', 'srv_count', 'dst_host_count', 'dst_host_srv_count',\n",
      "       'count', 'same_srv_rate', 'dst_host_same_srv_rate', 'protocol_type',\n",
      "       'dst_host_diff_srv_rate'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "adversarialFeatures(x_test,x_test_adv_fgsm,testdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Number of unique features changed : 41\n",
      " Number of average features changed per datapoint  20.140880056777856\n",
      " Top ten features : Index(['count', 'srv_count', 'dst_host_count', 'dst_host_srv_count', 'service',\n",
      "       'flag', 'same_srv_rate', 'protocol_type', 'dst_host_same_srv_rate',\n",
      "       'src_bytes'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "adversarialFeatures(x_test,x_test_adv_jsma,testdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22544/22544 [==============================] - 1s 57us/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "22544/22544 [==============================] - 1s 56us/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Accuracy :  0.003947835344215756\n",
      "Precision 4.7113136752746396e-05\n",
      "Recall :  0.003947835344215756\n",
      "F1-score :  9.294348137104302e-05\n",
      "Confusion Matrix : \n",
      "[[   0   43   63    0   17    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [   0   24   36    2   25    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [   0   16   31    1    7    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [   0   17   46    0   53    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [   0   13   52    2   34    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [   0   20   53    5   25    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [   0   33   88    5   31    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [   0   53  151    4   41    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [   0   20   88    4   19    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [   0   23   58    5   20    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [   0   46  109    0   40    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [   0  154  235    3   69    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [   0  202  240    1   43    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [   0  127  259   13  120    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [   0  105  472   13  146    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [   0  149  882    8  137    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [   0  131  442    9   99    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [   0   44  953   25  146    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [   0  206 1843  240  678    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [   0   97  403    9  381    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [   0  314  494   26  509    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [   0 5856 1639   51 3148    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]]\n",
      "Accuracy :  0.005633427963094393\n",
      "Precision 8.90770788290073e-05\n",
      "Recall :  0.005633427963094393\n",
      "F1-score :  0.0001752728610209398\n",
      "Confusion Matrix : \n",
      "[[  39    0    0    7   77    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [  26    0    0   13   48    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [  15    0    0    5   35    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [  21    0    0   49   46    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [  28    0    0   34   39    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [  38    0    0   26   39    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [  31    0    0   30   96    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [  54    0    0   28  167    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [  16    0    0   15  100    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [  22    0    0   18   66    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [  30    0    0   25  140    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [ 111    0    0   52  298    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [ 146    0    0   39  301    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [ 110    0    0  192  217    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [  87    0    0  175  474    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [  73    0    1  185  917    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [  22    0    0  108  551    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [  31    0    0  160  977    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [ 328    0    0  715 1924    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [  17    0    0  433  440    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [ 112    0    0  647  584    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [5918    0    4 3270 1502    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "dnnpredfgsm = dnnmodel.predict_classes(x_test_adv_fgsm,verbose=1)\n",
    "dnnpredjsma = dnnmodel.predict_classes(x_test_adv_jsma,verbose=1)\n",
    "printMetrics(y_test,dnnpredfgsm)\n",
    "printMetrics(y_test,dnnpredjsma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22544/22544 [==============================] - 1s 61us/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "22544/22544 [==============================] - 2s 74us/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Accuracy :  0.004036550745209368\n",
      "Precision 4.0220422060996495e-05\n",
      "Recall :  0.004036550745209368\n",
      "F1-score :  7.964704410097937e-05\n",
      "Confusion Matrix : \n",
      "[[  57    0    0    0   66    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [  50    0    0    0   37    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [  31    0    0    0   24    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [  70    0    0    0   46    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [  67    0    0    0   34    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [  65    0    0    0   38    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [  94    0    0    0   63    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [ 159    0    0    0   90    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [  67    0    0    0   64    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [  79    0    0    0   27    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [ 130    0    0    0   65    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [ 172    0    0    0  289    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [ 192    0    0    0  294    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [ 356    0    0    0  163    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [ 386    0    0    0  350    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [ 736    0    0    0  440    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [ 464    0    0    0  217    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [ 999    0    1    0  168    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [2256    0    0    0  711    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [ 771    0    0    0  119    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [1048    0    0    0  295    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [3948    0    0    0 6746    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]]\n",
      "Accuracy :  0.0044357700496806245\n",
      "Precision 4.38744615342024e-05\n",
      "Recall :  0.0044357700496806245\n",
      "F1-score :  8.68822085705968e-05\n",
      "Confusion Matrix : \n",
      "[[  62    0    0    0   61    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [  58    0    0    0   29    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [  31    0    0    0   24    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [  71    0    0    0   45    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [  63    0    0    0   38    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [  59    0    0    0   44    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [  97    0    0    0   60    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [ 161    0    0    0   88    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [  60    0    0    0   71    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [  74    0    0    0   32    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [ 128    0    0    0   67    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [ 173    0    0    0  288    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [ 190    0    0    0  296    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [ 351    0    0    0  168    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [ 386    0    0    0  350    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [ 738    0    0    0  438    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [ 462    0    0    0  219    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [1007    0    0    0  161    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [2309    0    0    0  658    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [ 782    0    0    0  108    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [1072    0    0    0  271    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [5078    0    5    0 5611    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "x_test_adv_cnn_fgsm = np.reshape(x_test_adv_fgsm, (x_test_adv_fgsm.shape[0],x_test_adv_fgsm.shape[1],1))\n",
    "x_test_adv_cnn_jsma = np.reshape(x_test_adv_jsma, (x_test_adv_jsma.shape[0],x_test_adv_jsma.shape[1],1))\n",
    "cnnpredfgsm = cnnmodel.predict_classes(x_test_adv_cnn_fgsm,verbose=1)\n",
    "cnnpredjsma = cnnmodel.predict_classes(x_test_adv_cnn_jsma,verbose=1)\n",
    "printMetrics(y_test,cnnpredfgsm)\n",
    "printMetrics(y_test,cnnpredjsma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22544/22544 [==============================] - 2s 104us/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "22544/22544 [==============================] - 2s 98us/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Accuracy :  0.00248403122782115\n",
      "Precision 2.7952911102603633e-05\n",
      "Recall :  0.00248403122782115\n",
      "F1-score :  5.452795576883401e-05\n",
      "Confusion Matrix : \n",
      "[[  10    6   95   12    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [  14    0   69    4    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [   8    0   40    7    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [  54    0   56    6    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [  46    0   53    2    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [  36    1   64    2    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [  46    0  110    1    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [  56   13  178    2    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [  35   38   51    7    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [  59    0   40    7    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [  83    2  106    4    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [  92    2  358    9    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [ 145   19  318    4    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [ 306    2  210    1    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [ 334   45  351    6    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [ 439   13  715    9    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [ 352   13  313    3    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [ 582   61  522    3    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [1752  266  915   34    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [ 655   10  221    4    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [ 952   10  335   46    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [3439    4 4959 2292    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]]\n",
      "Accuracy :  0.002528388928317956\n",
      "Precision 2.8018725676800746e-05\n",
      "Recall :  0.002528388928317956\n",
      "F1-score :  5.5185994814198244e-05\n",
      "Confusion Matrix : \n",
      "[[  13    6   87   17    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [  14    0   61   12    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [   8    0   36   11    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [  55    0   53    8    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [  54    0   42    5    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [  42    1   56    4    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [  47    0  105    5    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [  52   13  157   27    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [  31   38   53    9    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [  51    0   45   10    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [  81    2   91   21    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [  85    2  330   44    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [ 130   19  259   78    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [ 298    2  188   31    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [ 330   45  345   16    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [ 461   13  662   40    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [ 361   13  303    4    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [ 898   61  197   12    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [1835  267  788   77    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [ 653   10  216   11    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [ 963    9  305   66    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [3432   12 3540 3710    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "x_test_adv_lstm_fgsm = np.reshape(x_test_adv_fgsm, (x_test_adv_fgsm.shape[0],1,x_test_adv_fgsm.shape[1]))\n",
    "x_test_adv_lstm_jsma = np.reshape(x_test_adv_jsma, (x_test_adv_jsma.shape[0],1,x_test_adv_jsma.shape[1]))\n",
    "lstmpredfgsm = lstmmodel.predict_classes(x_test_adv_lstm_fgsm,verbose=1)\n",
    "lstmpredjsma = lstmmodel.predict_classes(x_test_adv_lstm_jsma,verbose=1)\n",
    "printMetrics(y_test,lstmpredfgsm)\n",
    "printMetrics(y_test,lstmpredjsma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def advMLEval(ML):\n",
    "    print(\"\\nFGSM\\n\")\n",
    "    printMetrics(y_test, ML.predict(x_test_adv_fgsm))\n",
    "    print(\"\\nJSMA\\n\")\n",
    "    printMetrics(y_test, ML.predict(x_test_adv_jsma))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.5245298083747338\n",
      "Precision 0.3644238525347155\n",
      "Recall :  0.5245298083747338\n",
      "F1-score :  0.42173369121852783\n",
      "Confusion Matrix : \n",
      "[[    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     1     0     3     7     0     1   111]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     1    11     0     2    73]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     1     6     0     1    47]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     1    52     0     0    63]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     1     0     2    33     0     6    59]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     2     9    27     0     6    59]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     2    12    32     0     2   109]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0    14     1     5    28     0     3   198]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0    37     0     3     6     0     0    85]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     1     1     4    18     0     0    82]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     1     0     2    16     0     1   175]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     1     1     7    14     0     0   438]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0    19     2    24    18     0     0   423]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     3     4    33    60     0     2   417]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0    44     1    30    96     0     6   559]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0   106     9    26   106     0    12   917]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0    31     7    16    86     0     5   536]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0    70    12    22   531     0    68   465]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0   268    23    33  1091     0   262  1290]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0    10     5     1   170     0   324   380]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     1     2     2   168     0   523   647]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     4     3   349     0   262 10076]]\n",
      "\n",
      "FGSM\n",
      "\n",
      "Accuracy :  0.4933907026259759\n",
      "Precision 0.3476048742439943\n",
      "Recall :  0.4933907026259759\n",
      "F1-score :  0.4007001177675698\n",
      "Confusion Matrix : \n",
      "[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    2    0    3    8    0    1  109]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    1   12    0    1   73]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    1    6    0    1   47]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    1   50    0    3   62]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    1    2   34    0    8   56]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    2    9   28    0    6   58]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    3   11   34    0    3  106]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0   14    1    5   28    0    3  198]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0   37    0    3    7    0    0   84]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    1    3    3   18    0    0   81]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    1    0    2   17    0    0  175]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    1    1    7   17    0    0  435]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0   19    1   25   22    0    0  419]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    3    4   33   64    0    3  412]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0   44    1   30  112    0    7  542]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0  107    9   25  115    0   20  900]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0   31    8   16  100    0   37  489]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0   70   13   22  542    0   82  439]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0  267   23   22 1104    0  328 1223]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0   10    5    1  176    0  270  428]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    6    2    2  156    0  399  778]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    1    4    2  423    0  781 9483]]\n",
      "\n",
      "JSMA\n",
      "\n",
      "Accuracy :  0.42352732434350604\n",
      "Precision 0.3390219688646361\n",
      "Recall :  0.42352732434350604\n",
      "F1-score :  0.35824063585709404\n",
      "Confusion Matrix : \n",
      "[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    1    0    2    7    0   13  100]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    1    1   11    0    9   65]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    1    0    7    0    4   43]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    1   26    0    8   81]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    2    2   30    0   23   44]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    6    4   30    0   19   44]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    5   10   33    0   11   98]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    1    4    4   27    0   33  180]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0   16    2    3   11    0    4   95]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    5    4   23    0    9   65]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    1    1   18    0    5  170]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    6    3   34    0   39  379]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0   18   14   30    0   92  332]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0   16   22  121    0   92  268]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    4   16   17  134    0   70  495]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0   44   31   23  178    0   66  834]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    3   16   15  128    0   28  491]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0   12   12   24  559    0   84  477]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0   14   68   13 1136    0  417 1319]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    1    5    1  221    0  311  351]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    2    0  254    0  577  510]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    4    4  956    0 1979 7751]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\envs\\tf1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "d:\\anaconda3\\envs\\tf1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\anaconda3\\envs\\tf1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\anaconda3\\envs\\tf1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#Machine learning\n",
    "LR = LogisticRegression()\n",
    "LR.fit(x_train,y_train)\n",
    "LR_Predprob=LR.predict_proba(x_test)\n",
    "LR_Pred=LR_Predprob.argmax(axis=1)\n",
    "printMetrics(y_test, LR_Pred)\n",
    "advMLEval(LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.24312455642299502\n",
      "Precision 0.3451015357240589\n",
      "Recall :  0.24312455642299502\n",
      "F1-score :  0.2724425084518677\n",
      "Confusion Matrix : \n",
      "[[  89    0    0    4    4    1    0    1    0    0    6    0    1    0\n",
      "     0    1    0    0    0    0    0   16]\n",
      " [  62    2    2    2    2    0    0    0    0    0    3    0    0    0\n",
      "     0    0    0    0    5    0    0    9]\n",
      " [  37    1    0    0    0    0    0    0    0    0    0    0    3    0\n",
      "     0    0    0    0    2    0    0   12]\n",
      " [  50    0    0    2    2    1    0    0    0    2   33    1    7    0\n",
      "     0    0    0    1    5    0    0   12]\n",
      " [  40    1    0    3    0    1    3    1    0    5   17    3    0    0\n",
      "     0    1    0    1   14    0    0   11]\n",
      " [  30    9    0    5    0    1    4    0    0    0    9    7    1    0\n",
      "     0    0    0    4   14    0    1   18]\n",
      " [  62    7    0   15    1    5    6    0    0    1   16    2   12    0\n",
      "     0    0    0    6    9    0    0   15]\n",
      " [  33    1    0   57    0    5   84    0    1    1   24    1    0    0\n",
      "     0    0    0   12   10    0    1   19]\n",
      " [  21    0    0   42    0    2   15    1    0    7   13    1    0    0\n",
      "     0    1    0   10    1    0    0   17]\n",
      " [  31    2    0    2    1    2   14    0    0    2   14    0    5    0\n",
      "     0    1    0    7    6    0    1   18]\n",
      " [  82    1    0    1    0    1   21    2    1    2   46    0    6    0\n",
      "     0    1    0    2    9    0    1   19]\n",
      " [ 208    3    0    4    0    0   86   13    5   11   70    1    5    0\n",
      "     0    1    0   11    8    0    1   34]\n",
      " [ 135   13    0   24    0    2  126    9    8   11   20    2    3    0\n",
      "     0    6    1   50   11    0    1   64]\n",
      " [  65   26    0    6    1    1  102    4   12    8   33    0    0    0\n",
      "     0    9    2   55   53    0   25  117]\n",
      " [ 208   23    0   44    0    4   70    2    1   17   42    5    1    0\n",
      "     0    0    5   82   79    0   19  134]\n",
      " [ 365   20    0   23    0    4   11   55    0   14  176   13    3    0\n",
      "     0   91    4   94   61    0    9  233]\n",
      " [ 214   11    1   17    0    6    3    4    0    4  114    9    0    0\n",
      "     0   30    2    2   50    0    0  214]\n",
      " [ 128   35    5   69    0    8   13    0    0    3   69    6    0    0\n",
      "     0    9    2    1  635    0    1  184]\n",
      " [ 306   69   12  275    0    9    5   16    0    0  144    0    3    0\n",
      "     1   40   14    0 1293    0    0  780]\n",
      " [  95    9    1   10    0    6    1    0    0    0   11    0    0    0\n",
      "     0    0    0    0  346    0    0  411]\n",
      " [ 270    3    2   16    0    2    4    0    0    1   41    0    0    0\n",
      "     0    0    0    0  439    0    0  565]\n",
      " [5892    4    2   32    0    3   15   31   17    0   15    0    2    0\n",
      "     0   22    6    5  704    0    2 3942]]\n",
      "\n",
      "FGSM\n",
      "\n",
      "Accuracy :  0.029630943931866573\n",
      "Precision 0.4916176629658009\n",
      "Recall :  0.029630943931866573\n",
      "F1-score :  0.013941804657510161\n",
      "Confusion Matrix : \n",
      "[[   0    0    0    0   31    3    0    3    0    0    2    0    0   22\n",
      "    40    0    0    1    0    5   16    0]\n",
      " [   0    0    0    0   18    2    0    1    0    0    2    0    0    7\n",
      "    34    0    0    0    0    7   16    0]\n",
      " [   0    0    0    0   16    6    0    0    0    0    1    0    0   11\n",
      "    11    0    0    0    0    0   10    0]\n",
      " [   0    0    0    0   14    0    0    0    0    0    2    0    0   26\n",
      "    26    0    0    0    0    2   46    0]\n",
      " [   0    0    0    0    5    4    0    0    0    0    0    0    0   19\n",
      "    35    0    2    0    0    1   35    0]\n",
      " [   0    0    0    1   11    2    0    0    0    0    0    1    0   16\n",
      "    33    0    0    0    0    6   33    0]\n",
      " [   0    0    0    0   28    1    0    0    0    0    0    0    0   11\n",
      "    97    0    0    0    0    1   19    0]\n",
      " [   0    0    0    0   86   11    0    4    0    0   19    0    0   21\n",
      "    76    0    0    1    0    8   23    0]\n",
      " [   0    0    0    0   50    7    0    5    0    0    1    0    0    8\n",
      "    37    0    1    0    0    9   13    0]\n",
      " [   0    0    0    0   22    5    0    2    0    0    4    0    0    5\n",
      "    45    0    0    1    0   10   12    0]\n",
      " [   0    0    0    0   74    2    0    8    0    0   15    0    0   19\n",
      "    59    0    0    2    0    6   10    0]\n",
      " [   0    0    0    0   89    2    0   25    0    0   11    1    0   16\n",
      "   228    0    0   24    0    7   58    0]\n",
      " [   0    0    0    0   56    2    0   12    0    0    0    0    0   53\n",
      "   190    0    2   31    0   17  123    0]\n",
      " [   0    1    0    0   97    6    0    3    0    0    3    0    0   27\n",
      "   205    0    1    9    0   11  156    0]\n",
      " [   0    1    0    0  133    5    0    5    0    0    4    0    0  166\n",
      "   249    0    6    3    0   22  142    0]\n",
      " [   0    0    0    0  134   10    0   39    0    0    5    0    0  289\n",
      "   462    0   26   13    0   14  184    0]\n",
      " [   0    0    0    0   94   41    0    0    0    0    1    1    0   70\n",
      "   385    0   14    0    0    3   72    0]\n",
      " [   0    0    0    0  622   26    1    2    1    0    2    0    0   57\n",
      "   275    0    7    2    0   54  119    0]\n",
      " [   0    1    0    1  742  191    0    8    0    0    9    1    0  136\n",
      "   999    0   40   43    0  255  541    0]\n",
      " [   0    0    0    0  180   44    0    0    0    0    4    0    0   54\n",
      "   379    0   10   28    0   12  179    0]\n",
      " [   0    0    0    0  340   43    1    1    0    0    3    0    0  106\n",
      "   462    0   17    4    0   33  333    0]\n",
      " [   0    7    0    0 3931 1051    0  207    0    0   31    0    0  144\n",
      "  3481    0   30   73    0  386 1349    4]]\n",
      "\n",
      "JSMA\n",
      "\n",
      "Accuracy :  0.019339957416607524\n",
      "Precision 0.3606704234387007\n",
      "Recall :  0.019339957416607524\n",
      "F1-score :  0.020261695640454724\n",
      "Confusion Matrix : \n",
      "[[   0    4    1    0   31   12    5   13    4   14    0    0   18    0\n",
      "     7    0    6    5    0    1    1    1]\n",
      " [   0    6    2    0   24    7    1    6    3   16    0    0    6    0\n",
      "     8    0    4    3    0    0    1    0]\n",
      " [   0    2    1    0   15   10    0    3    1    7    0    0    6    0\n",
      "     2    0    0    5    0    1    1    1]\n",
      " [   0    6    1    0   42   34    1    5    2    8    1    0    5    1\n",
      "     3    0    5    1    0    1    0    0]\n",
      " [   0   17    6    0   17   19    1    7    0   10    0    0    2    2\n",
      "     9    0    3    3    0    1    2    2]\n",
      " [   0   18    2    0   28   16    1    7    0    5    1    0    2    6\n",
      "    10    0    4    1    0    2    0    0]\n",
      " [   0   23    2    0   29   20    3    4    0   17    1    0    3    4\n",
      "    13    0    3   32    0    0    2    1]\n",
      " [   5   33    2    0   52   41    2   35    1   12    0    0   16    2\n",
      "    20    0    3    9    0    1   15    0]\n",
      " [   1    6    0    0   15   18    1   48    1    6    2    0   11    6\n",
      "     5    0    4    3    1    2    1    0]\n",
      " [   1   17    0    0   19   15    1    5    1    9    3    0    9    7\n",
      "     6    0    6    4    0    0    2    1]\n",
      " [   0   12    0    0   26   27    2    7    1   19    1    0   43   10\n",
      "    13    0   16   11    1    0    6    0]\n",
      " [   1   32   14    0   91   75   36   13    1   18    1    1   20   46\n",
      "    29    0   56   17    0    1    3    6]\n",
      " [   0   16    0    0  143   86   19   45    5   21    1    0   28   15\n",
      "    25    0   74    7    0    0    1    0]\n",
      " [   0   44    2    0  153   66   16   27    9   23    1    0   34   12\n",
      "    28    3   62   32    0    1    4    2]\n",
      " [   0   35    1    0  140  200   11   68   18   39   14    0   42   53\n",
      "    31    1   47   32    0    2    1    1]\n",
      " [   2   37    7    0  132  328   15  104   20   54   12    3   97  158\n",
      "    53    0   96   44    0    0   13    1]\n",
      " [   2   80    8    1   53  162   14   60    0   42   28    8   26   25\n",
      "    21    0  111   30    0    0    4    6]\n",
      " [   2  135   14    0  138  361   46  166    2   91    8    1   77   25\n",
      "    12    0   29   39    7    1   10    4]\n",
      " [  24  169   60   12  519  370  303  599   11  209   27   33  172   63\n",
      "   132    0   80   79    4    8   82   11]\n",
      " [   0   50   32    1  128  139   56  263    1   41    9    0   37   25\n",
      "    11    0   17   58    4    0   13    5]\n",
      " [   3   52   45    2  371  176   57  319    2   43   24    0   51   68\n",
      "    41    0   19   45    1    0   15    9]\n",
      " [   9  478  105    0 5160  443  264 1811   23   81   19    2  317  359\n",
      "   963    0   91  349    1   15   98  106]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\envs\\tf1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\anaconda3\\envs\\tf1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "GNB = GaussianNB()\n",
    "GNB.fit(x_train,y_train)\n",
    "GNB_Predprob=GNB.predict_proba(x_test)\n",
    "GNB_Pred=GNB_Predprob.argmax(axis=1)\n",
    "printMetrics(y_test, GNB_Pred)\n",
    "# np.savetxt(LOG_PATH+'GaussianNB/predict_proba.txt', GNB_Predprob, fmt='%06f')\n",
    "# np.savetxt(LOG_PATH+'GaussianNB/confusion_matrix.txt', confusion_matrix(y_test,GNB_Pred), fmt='%01d')\n",
    "advMLEval(GNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.595457771469127\n",
      "Precision 0.5441319054700705\n",
      "Recall :  0.595457771469127\n",
      "F1-score :  0.5560597535494152\n",
      "Confusion Matrix : \n",
      "[[    5     2     2     0     0     0     0     2     0     0     0     0\n",
      "      3     0     2     5     0     2     5    13    37    45]\n",
      " [    2     2     3     0     1     0     2     1     0     0     0     0\n",
      "      2     1     1     3     1     3     2    12    37    14]\n",
      " [    0     0     0     7     0     0     0     0     0     0     0     0\n",
      "      0     0     0     2     1     0     2    13    20    10]\n",
      " [    0     3     1    24     0     0     1     0     0     0     0     0\n",
      "      2     0     1     9     1     2    38    15    13     6]\n",
      " [    2     2     0    11     1     0     0     0     1     1     0     0\n",
      "      1     2     1     6     1     4    15     9    26    18]\n",
      " [    0     1     1     2     1     0     2     1     3     1     2     1\n",
      "      2     0     0     6    12     8     5    16    24    15]\n",
      " [    0     1     1     5     2     3     1     1     0     0     1     1\n",
      "      1     2     3    24     3    18    12    10    45    23]\n",
      " [    0     3     4     6     0     2     1     5     4     0     3     1\n",
      "      1     3     5    21     3     9    18     8    22   130]\n",
      " [    1     0     1     2     0     2     0     1     1     1     4     2\n",
      "      1     0     2    38     1     6    11     6    12    39]\n",
      " [    1     0     2     3     0     1     1     1     2     1     3     0\n",
      "      3     1     9     5     2     3    10     4     5    49]\n",
      " [    0     0     0     0     0     3     0     0     0     0     9     3\n",
      "      8     1     3     8     2     5     8    22    17   106]\n",
      " [    1     0     1     0     0     1     0     0    19     1     6     6\n",
      "     16    26    37    12    11    51    13    42   138    80]\n",
      " [    1     6    17     1     3     3     1     1     6     1     4    12\n",
      "     20    31   127    42    12    20    11    25    89    53]\n",
      " [    2     0     7     1     1     3     1     0     5     0     2     5\n",
      "      8    12   115    45    14    30    69    13    58   128]\n",
      " [    0     0    61    14     1     7     0     2    42     0     6     7\n",
      "      3     9    88    77    15    35    71    12   170   116]\n",
      " [    0     1   139    17     2     1     2     0    36     1     2     4\n",
      "      3    11    71   181    63    44   118    33   174   273]\n",
      " [    0     1     9    24     0     4     1     0    13     0     2     2\n",
      "      0     2    11    70   112    10    63    12   182   163]\n",
      " [    1     0     7     3     1     2     5     0    10     0     1     2\n",
      "      0    14    15    67    33   103   513    68   171   152]\n",
      " [    0     7     7     5     1     0    11     2     5     0    12     4\n",
      "      7    28    74   227    83    53  1400   209   296   536]\n",
      " [    0     1     1     0     0     0     0     0     8     0    21     0\n",
      "      0    12    41    12    19    15   121   423   184    32]\n",
      " [    2     0     1     0     0     0     0     0     0     0     1     1\n",
      "      2     1     6    10     2    19    97   110   878   213]\n",
      " [    1     8     8     0     0     0     0     0     0     0     1     0\n",
      "      0     1     8     9     6    34    63    57   346 10152]]\n",
      "\n",
      "FGSM\n",
      "\n",
      "Accuracy :  0.45568665720369056\n",
      "Precision 0.44712307443423827\n",
      "Recall :  0.45568665720369056\n",
      "F1-score :  0.44231948727647574\n",
      "Confusion Matrix : \n",
      "[[   2    1    2    2    0    0    0    1    1    2    0    1    1    0\n",
      "     1    0    4    1    0    9   31   64]\n",
      " [   1    2    4    0    0    0    1    1    0    0    0    0    3    4\n",
      "     1    0    0    0    4    9   43   14]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    1    3    0    1    6   31   13]\n",
      " [   0    0    2    1    0    0    1    0   26    0    0    4    0    0\n",
      "     0    6    1    1   10   12   42   10]\n",
      " [   3    0    0    0    0    0    0    0    0    2    0    1    0    2\n",
      "     0    5    1    2   13   15   47   10]\n",
      " [   0    0    1    0    1    0    4    0    1    1    0    1    2    0\n",
      "     0    4    5    7   12   16   36   12]\n",
      " [   0    0    1    0    2    2    1    1    0    0    0    2    1    1\n",
      "     2   22    1   19   17    9   54   22]\n",
      " [   1    1    2    1    1    3    1    2    4    0    0    6    0    2\n",
      "     4   19    2    9   21   12   33  125]\n",
      " [   0    2    0    1    0    2    0    0    0    0    0    1    1    0\n",
      "     1   40    0    6   10    5   20   42]\n",
      " [   1    0    2    1    0    2    1    1    1    1    0    2    1    0\n",
      "     8    5    1    5   11    4    7   52]\n",
      " [   0    0    0    0    0    2    1    0    0    0    4    1    6    2\n",
      "     4    4    2   16    8   24   25   96]\n",
      " [   3    0    2    0    0    1    2    0   13    1    2    0    8    0\n",
      "    40    7   10   94   16   40   90  132]\n",
      " [   1    5   16    1    1    5    1    0    2    0    2    0    3    5\n",
      "   128   34   10   78   28   12   54  100]\n",
      " [   0    0    3    0    1    4    2    2    0    0    2    3    4    6\n",
      "   115   30   13   50   68    7   44  165]\n",
      " [   0    0    2    2    2    7    1    3    0    0    1    8    1   10\n",
      "    95   83    6   55   74   16  106  264]\n",
      " [   0    1    4    1    0    2    0    1    0    0    0    4    2    9\n",
      "    85  132   41  105  115   32  139  503]\n",
      " [   0    0    0    1    0    4    1    0    0    0    0    3    1    0\n",
      "    11   38   28  116   49   27  233  169]\n",
      " [   1    0    0    0    1    2    3    1    0    0    0    3    2   13\n",
      "    16   63   20   68  557   60  184  174]\n",
      " [   0    1    2    1    3    0    6    1    4    2    2   52    6   36\n",
      "    77  281   76   50 1244  313  275  535]\n",
      " [   0    0    1    0    0    0    0    0    0    0    0    1    0   13\n",
      "    33   11   19   11  207  311  236   47]\n",
      " [   2    1    1    0    4    0    0    0    0    1    0    7    1    4\n",
      "     9    5    2   15  183  312  498  298]\n",
      " [   2   12    8    0   57    0    2    0    0    0    0    2    3    1\n",
      "     3    7    4   52  379  718 1569 7875]]\n",
      "\n",
      "JSMA\n",
      "\n",
      "Accuracy :  0.30491483321504614\n",
      "Precision 0.3834605079671612\n",
      "Recall :  0.30491483321504614\n",
      "F1-score :  0.3254575089702867\n",
      "Confusion Matrix : \n",
      "[[   5    1    1    0    0    0    0    0    2    2    1    2    1    3\n",
      "     2    5    9    0    5    4   31   49]\n",
      " [   5    3    1    0    0    1    1    0    1    0    1    0    3    1\n",
      "     3    6    6    0    3   14   27   11]\n",
      " [   2    1    0    0    0    1    0    0    0    0    2    1    0    1\n",
      "     0    2    7    0    9    7   15    7]\n",
      " [   1    3    1    1    0    7    0    0    1    0   10    3    2   12\n",
      "     3   18    6    1   27    7    3   10]\n",
      " [   3    1    0    0    0    0    0    0    2    0    4    2    0    0\n",
      "     2    6    2    3   28    5   13   30]\n",
      " [   0    0    1    0    2    5    0    1    0    3    3    1    0    1\n",
      "     2   10   12    3   10   13   14   22]\n",
      " [   0    3    1    0    1    4    2    0    2    0    5    0    1    2\n",
      "     5   21    6   17   14   10   33   30]\n",
      " [   1    1    4    0    0    6    0    0    3    2    7    2    0    2\n",
      "    12   21    9    8   26    5   17  123]\n",
      " [   0    2    1    0    0    2    0    1    1    1    6    1    1    1\n",
      "     7   38    3    7   17    3    6   33]\n",
      " [   1    1    1    1    1    2    0    3    2    1    4    2    0    2\n",
      "    15    3    3    5   14    3    8   34]\n",
      " [   0    0    4    0    0    4    2    1    3    0    4    1    5    2\n",
      "    15    6   13   10   13   12    6   94]\n",
      " [   0    4    3    0    0    5    0    1    8   10    8    3    8    0\n",
      "    84   13   25   38   12    4  106  129]\n",
      " [   0   11   14    2    0    6    1    1    7   23    6   25    1    2\n",
      "   137   47   14   21   18    3   83   64]\n",
      " [   1   12    3    0    2    4    0    2    5   17    7   13    0    4\n",
      "    97   54    9   24   83    7   51  124]\n",
      " [   2   11   19    0    4    7    1    9   34   17   53   10    6    8\n",
      "    80   45   18   27   95    7  104  179]\n",
      " [   0    7   57    0    4    8    0    4   20   13   99    6    5    6\n",
      "   122  102   49   59  207   12  168  228]\n",
      " [   0    4    5    0    3    6    0    2    0    2    7    3    2    2\n",
      "   104   38   29    8   98   12  143  213]\n",
      " [   5   10    7    0    0    5    3    2    0    1    4    1    0    7\n",
      "    23   70   22   81  559   45  125  198]\n",
      " [  15   12    9    2    0    8    2    2    8    0   31    6   10   13\n",
      "    94  281  123  144 1133  191  263  620]\n",
      " [   2    0    0    0    0    0    0    1    0    0   33    0    0    1\n",
      "    35   19   10   43  225  292  168   61]\n",
      " [   7    3    4    0    0    3    0    2    9    1    3    5    1    2\n",
      "     8   23   21   29  225  117  665  215]\n",
      " [ 100   20  116    0    2   10    0   25  302   69   36   65   96   24\n",
      "   425  301 1497  131  948  328 1737 4462]]\n"
     ]
    }
   ],
   "source": [
    "KNN = KNeighborsClassifier()\n",
    "KNN.fit(x_train,y_train)\n",
    "KNN_Predprob=KNN.predict_proba(x_test)\n",
    "KNN_Pred=KNN_Predprob.argmax(axis=1)\n",
    "printMetrics(y_test, KNN_Pred)\n",
    "# np.savetxt(LOG_PATH+'KNeighborsClassifier/predict_proba.txt', KNN_Predprob, fmt='%06f')\n",
    "# np.savetxt(LOG_PATH+'KNeighborsClassifier/confusion_matrix.txt', confusion_matrix(y_test,KNN_Pred), fmt='%01d')\n",
    "advMLEval(KNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DT = DecisionTreeClassifier()\n",
    "DT.fit(x_train,y_train)\n",
    "DT_Predprob=DT.predict_proba(x_test)\n",
    "DT_Pred=DT_Predprob.argmax(axis=1)\n",
    "printMetrics(y_test, DT_Pred)\n",
    "advMLEval(DT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.49525372604684176\n",
      "Precision 0.35350586044166044\n",
      "Recall :  0.49525372604684176\n",
      "F1-score :  0.39874298034379224\n",
      "Confusion Matrix : \n",
      "[[    0     2     0     1     0     0     0     0     1     0     0     1\n",
      "      0     0     0     2     1     1     9     2    11    92]\n",
      " [    0     1     0     1     2     0     0     0     1     0     0     1\n",
      "      1     0     0     0     0     0     6     1     9    64]\n",
      " [    0     0     0     0     0     0     0     1     7     0     0     0\n",
      "      0     0     0     0     0     0     6     0     0    41]\n",
      " [    0     0     0     0     2     0     0     0    24     0     1     0\n",
      "      1     0     0     0     0     0    30     2     4    52]\n",
      " [    0     0     1     0     0     1     0     0    12     0     2     0\n",
      "      0     0     0     3     3     1    12     0     4    62]\n",
      " [    1     0     0     0     0     1     0     0     6     0     0     0\n",
      "      0     0     0     6     5     3    15     1    11    54]\n",
      " [    0     5     0     1     0     1     0     1     7     2     0     0\n",
      "      0     0     0     1     5     1    20     0    64    49]\n",
      " [    0     2    10     0     0     5     0     0    12     1     0     1\n",
      "      2     0     0    14     3     2    17     1    57   122]\n",
      " [    0     0     3     0     0     6     2     2     5     2     0     0\n",
      "      0     0     0    37     1     0     7     0    15    51]\n",
      " [    0     3     7     0     0     1     4     2     4     1     0     2\n",
      "      1     0     0     0     3     0    10     0    26    42]\n",
      " [    0     1    19     0     0     0     8     0     0     0     0     4\n",
      "      0     0     0     0     1     0    17     0    64    81]\n",
      " [    0     1    42     0     0     2    10     1     0     0     0    38\n",
      "      1     0     0     1     5     1    12     0    43   304]\n",
      " [    0     0    78     2     0     5    13     0     1     0     2    57\n",
      "      5     0     1    20    20     2    31     1    38   210]\n",
      " [    0     0    30     3     0     5     3    11     1     0     1    17\n",
      "      5     0     3     4    13     6    72     1    55   289]\n",
      " [    0     0    26     0     0    13     1     5    11     0     5    17\n",
      "     48     0    39    48    10     8    93     2    91   319]\n",
      " [    0     0     5     5     0    11     4     2    17     0     4    61\n",
      "     64     0    53    17     6     9   115     3   247   553]\n",
      " [    0     0     8     1     0     3     0     2    39     0     5   101\n",
      "      6     0     2    17     3     2    81     1    22   388]\n",
      " [    0     1    19     0     0     5     0     0    16     0     3    10\n",
      "      2     0     3    66     4     1   240    57    25   716]\n",
      " [    0     0     4     1     0     1     0     0    33     0     1     1\n",
      "      1     0     5   261    31     1   746    31    32  1818]\n",
      " [    0     0     1     0     0     0     0     0    42     0     0     0\n",
      "      2     0     0    12     0     1   247    27     8   550]\n",
      " [    0     0     0     4     0     0     0     0     9     0     2     0\n",
      "      0     0     0    10     2     1   319    64    45   887]\n",
      " [    2     0     1     3     0     0     0     0     3     1     2     0\n",
      "      3     0     1     0    14     5   306    66    51 10236]]\n",
      "\n",
      "FGSM\n",
      "\n",
      "Accuracy :  0.14101312987934705\n",
      "Precision 0.22688539891536696\n",
      "Recall :  0.14101312987934705\n",
      "F1-score :  0.1668725411717906\n",
      "Confusion Matrix : \n",
      "[[   0    1   62    0    0    2    0    0    0    6    0    1    0    0\n",
      "     0    7    0   18   12    0    0   14]\n",
      " [   0    0   37    0    0    0    0    0    0    4    0    0    0    0\n",
      "     0    5    0   13   13    0    2   13]\n",
      " [   0    0   31    0    0    1    0    0    0    1    0    0    0    0\n",
      "     0    7    0    0    8    0    1    6]\n",
      " [   0    0   27    0    0    0    0    0    1    1    0    1    0    0\n",
      "     0   25    0    3    8    0    1   49]\n",
      " [   0    0   25    0    0    0    0    0    1    2    1    0    0    0\n",
      "     0   16    0   10    8    6    4   28]\n",
      " [   0    0   34    0    0    0    0    0    0    2    0    0    0    0\n",
      "     0   13    0   13   18    2    1   20]\n",
      " [   0    0   76    0    0    0    0    0    1    2    0    0    0    0\n",
      "     0    8    0    9   29    8    5   19]\n",
      " [   0    0  133    0    0    0    0    0    0    3    0    3    0    0\n",
      "     0   13    0   22   39    5    5   26]\n",
      " [   0    0   92    0    0    0    0    0    0    2    0    1    0    0\n",
      "     0    7    0    3   11    3    1   11]\n",
      " [   0    0   59    0    0    0    0    0    0    1    0    2    0    0\n",
      "     0    5    0   12   14    2    1   10]\n",
      " [   0    0  110    0    0    1    0    0    1    2    0    1    0    0\n",
      "     1   13    0   22   24    1    4   15]\n",
      " [   0    0  159    1    0    0    0    0    0   11    0    1    0    0\n",
      "     0    3    0  176   49    3    4   54]\n",
      " [   0    0  196    1    0    1    0    1    2    5    0    1    1    0\n",
      "     0   10    0  153   51    2    5   57]\n",
      " [   0    1  141    0    0    2    0    1    0    9    0    0    2    0\n",
      "     0   11    0  105   55    5    5  182]\n",
      " [   0    0  162    0    0    1    0    0    0   13    0    1    1    0\n",
      "     0  160    1   98   91    8    3  197]\n",
      " [   0    0  318    0    0    0    0    2    0   45    0    1    1    0\n",
      "     0  281    1  123  133    6    5  260]\n",
      " [   0    0  186    0    0    0    0    0    0   19    0    0    0    0\n",
      "     0   67    0  177   99   10   10  113]\n",
      " [   0    0  273    0    0    0    0    0    0   32    0    0    0    1\n",
      "     0   38    2  104  105   47   48  518]\n",
      " [   0    0  967    0    0    8    0    2    0   65    3    2    1    0\n",
      "     5  178    2  320  328  176   93  817]\n",
      " [   0    0  124    0    0    6    0    0    1    7    1    1    1    1\n",
      "     1   67    0   69   49   83   94  385]\n",
      " [   0    0  166    0    0    0    0    1   13   15    6    7    1    0\n",
      "     0   71    0  227   75  128   59  574]\n",
      " [   0    2 2305    2    0   10    0    0   24  304    6   26   72    2\n",
      "    98  404    0 1931 2259  836  123 2290]]\n",
      "\n",
      "JSMA\n",
      "\n",
      "Accuracy :  0.16580908445706175\n",
      "Precision 0.2782630913964723\n",
      "Recall :  0.16580908445706175\n",
      "F1-score :  0.20443358702559108\n",
      "Confusion Matrix : \n",
      "[[   0    0   59    2    7    5    6    0    0    5    3    0    0    0\n",
      "     0   11    0    2    2    0    0   21]\n",
      " [   0    0   43    0    0    3    3    0    2    4    1    0    0    0\n",
      "     0    7    0    2    6    1    1   14]\n",
      " [   0    0   23    1    1    2    2    0    7    2    5    0    0    2\n",
      "     0    4    0    0    1    1    0    4]\n",
      " [   0    0   59    1    2    2    1    0   23    0    0    1    0    1\n",
      "     0    0    2    4   11    0    0    9]\n",
      " [   0    0   23    0    6   10    2    1   13    0    1    0    0    1\n",
      "     0    7    0    1   11    3    1   21]\n",
      " [   0    0   25    0    7    5    3    0    6    4    2    0    0    1\n",
      "     0    6    4    2   15    3    0   20]\n",
      " [   0    0   68    0    5    7    4    1    7    5    2    0    0    0\n",
      "     0    0    2    1   20    1    6   28]\n",
      " [   0    0   58    0    4   12    4    0   12    8    0    0    0    0\n",
      "     0   18    1    2   20    2   42   66]\n",
      " [   0    0   18    0    2   11    0    2    7    2    1    0    0    0\n",
      "     0   37    0    0    9    0   12   30]\n",
      " [   0    0   24    0    0   14    1    0    8    4    1    0    0    1\n",
      "     0    1    4    2    8    1   19   18]\n",
      " [   0    0   55    0    6   18    1    1    7    2    1    0    0    1\n",
      "     0    2    6    2   21    0   22   50]\n",
      " [   0    1  129    1   12   39    0    1    6    2    1    3    0    2\n",
      "     1   15    5   25   59    0   12  147]\n",
      " [   0    0  177    1   32    9    3    3   10    0    3    0    0    2\n",
      "     4   33    9   14   15    0    0  171]\n",
      " [   0    0  174    1   20   35    5    3    2    1    4    0    0    1\n",
      "     3   12    9   26   52    8   15  148]\n",
      " [   0    0  188    0   22   50   13    5   12    1   16    1    0    8\n",
      "    11   78    5   18   56    4    7  241]\n",
      " [   0    0  211    2   47   84   12    4   21    5   42    3    0    0\n",
      "     8   91    6   35  100   10   31  464]\n",
      " [   0    0  114    0   45   61   19    2   39    1   31   11    0    5\n",
      "     0   34    7   11   54    2    8  237]\n",
      " [   0    0  124    2   36  383   16    0   16    1   61    5    0   12\n",
      "     1   75    5   15  125   81    5  205]\n",
      " [   0    0  354    2   29  464   87    0   32   22  141   38    0   10\n",
      "     6  366   33   30  464  158   22  709]\n",
      " [   0    0   64    0    5   91   16    2   37    1   14    6    0    2\n",
      "     0   97    7    5  116   85   13  329]\n",
      " [   0    0  132    8   14  101   12    2    4    7   16    7    0    7\n",
      "     0  207   13   14  119  103   13  564]\n",
      " [   0    1 4533    4  405  903   99   17    4  612   81   21    0   61\n",
      "    25   52  131  112  380  194   62 2997]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\envs\\tf1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\anaconda3\\envs\\tf1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\anaconda3\\envs\\tf1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "AB = AdaBoostClassifier(n_estimators=100)\n",
    "AB.fit(x_train,y_train)\n",
    "AB_Predprob=AB.predict_proba(x_test)\n",
    "AB_Pred=AB_Predprob.argmax(axis=1)\n",
    "printMetrics(y_test, AB_Pred)\n",
    "advMLEval(AB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.6418115684882896\n",
      "Precision 0.5869439437808608\n",
      "Recall :  0.6418115684882896\n",
      "F1-score :  0.5820581652503813\n",
      "Confusion Matrix : \n",
      "[[    0     1     0     0     0     0     0     0     0     0     0     0\n",
      "      0     1     0     2     0     3     1     3    42    70]\n",
      " [    0     3     2     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     1     0     5     5     2    53    16]\n",
      " [    0     0     1     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     1     0     0     2     4    37    10]\n",
      " [    0     0     1     1     0     0     0     0     0     0     0     0\n",
      "      0     0     1     6     0     2    41     5    50     9]\n",
      " [    0     0     0     0     1     0     0     0     0     0     0     0\n",
      "      0     0     1     1     1    12    27     4    36    18]\n",
      " [    0     0     0     0     0     0     0     0     0     0     1     0\n",
      "      1     0     1     1     8     9    20     5    37    20]\n",
      " [    0     0     0     0     1     0     0     1     1     0     0     0\n",
      "      7     0     0    16     2     5    15     2    32    75]\n",
      " [    0     0     0     0     0     0     0     5     1     0     0     0\n",
      "      3     0     5     7    36     4    19     2    63   104]\n",
      " [    0     0     0     0     0     0     2     0     0     0     4     0\n",
      "      1     2     1     5     1     1     4     0    69    41]\n",
      " [    0     0     0     0     0     0     0     1     1     0     5     1\n",
      "      7     0     1     1     3     4     9     1    26    46]\n",
      " [    0     0     0     0     0     0     0     0     0     0    12     2\n",
      "     10     1     4     4     0     2     9     0    42   109]\n",
      " [    0     1     0     0     0     0     0     1     0     0    15     7\n",
      "     13     5    12    14    15    12    13     0    39   314]\n",
      " [    0     1     0     0     0     0     0     0     0     1     9    17\n",
      "     18    12     9    25    17    59    23     3   109   183]\n",
      " [    0     0     0     0     0     0     0     0     0     2     1     3\n",
      "      3     8    17    41     9    19   102     4    68   242]\n",
      " [    0     0     0     0     0     0     0     0     0     0     8     1\n",
      "      7     3    54    44    12    16   114     6   187   284]\n",
      " [    0     0     0     0     0     0     2     0     0     0    42    22\n",
      "      1     0    20   194    24    73   170     4   219   405]\n",
      " [    0     0     0     0     0     1     0     0     0     0     5     3\n",
      "      0     0     7    65   114    14   117    20    74   261]\n",
      " [    0     0     0     0     1     0     0     0     0     0     3     2\n",
      "      1     0     8    16     8   460   337    19   111   202]\n",
      " [    0     0     0     0     1     0     0     0     0     0     1     1\n",
      "      0     0     0    11     8    67  1787   158   466   467]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     1    35   201   366   225    62]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     1     2     2     7    53    96   997   185]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     1    27    29   196 10441]]\n",
      "\n",
      "FGSM\n",
      "\n",
      "Accuracy :  0.21260645848119233\n",
      "Precision 0.29235323370287764\n",
      "Recall :  0.21260645848119233\n",
      "F1-score :  0.20902783531853839\n",
      "Confusion Matrix : \n",
      "[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    1    0    9   55    4   31   23]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    1    7   34    3   26   16]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    1    1   30    2   18    3]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    1    2    2   36    5   33   37]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    1    2   10   38    4   27   19]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    3    2    5   37    1   31   24]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    1   16   71    3   46   20]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    1    3   17  108    7   88   25]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0   23    2    6   60    5   24   11]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    2    2   15   49    1   25   12]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     1    2    1   18  104    3   38   28]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    1    0\n",
      "     0    2    2  168   86    7   89  106]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    7   10  115  127    8   90  129]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    2    6   57  153   16   98  187]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0   28   27   77  317   11  119  157]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0   97   60   92  570    7  168  182]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0   31   71  142  266    2   99   70]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0   72   38   99  703   16   78  162]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     1   70   16  153 1859   51  298  519]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     1    3    7   12  538    1  118  210]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     1   17    5   24  573   15  205  503]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    54    9   24  344 3130  117 4555 2461]]\n",
      "\n",
      "JSMA\n",
      "\n",
      "Accuracy :  0.3864886444286728\n",
      "Precision 0.4350777325781599\n",
      "Recall :  0.3864886444286728\n",
      "F1-score :  0.3788294924212999\n",
      "Confusion Matrix : \n",
      "[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     1    0    0    6   16    8   32   60]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    5   26    5   35   16]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    1    4   10    3   18   19]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    1    0\n",
      "     1    6    0    5   48    6   37   12]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     1    1    1    7   33    3   34   21]\n",
      " [   0    0    0    0    0    0    0    0    0    0    1    0    1    0\n",
      "     0    0    6   14   27    6   29   19]\n",
      " [   0    0    0    0    0    0    0    1    0    0    0    0    4    0\n",
      "     0   15    2    4   25    3   33   70]\n",
      " [   0    0    0    0    0    0    0    4    0    0    0    0    0    0\n",
      "     4   18    6    6   26    2   58  125]\n",
      " [   0    0    0    0    0    0    0    0    0    0    1    0    1    2\n",
      "     0   19    1    2   16    2   44   43]\n",
      " [   0    0    0    0    0    0    0    1    0    0    3    0    4    0\n",
      "     2    0    2   13   10    3   22   46]\n",
      " [   0    0    0    0    0    0    0    0    0    0   13    0    9    0\n",
      "     4    1    0    6   14    1   46  101]\n",
      " [   0    0    0    0    0    0    0    0    0    0   12    0   16    3\n",
      "    10    8   17   24   21    4   65  281]\n",
      " [   0    0    0    0    0    0    0    0    0    0   13    0   28    0\n",
      "     7   24   16   94   64    3   95  142]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    5    1\n",
      "     4   13   11   73  137    4  126  145]\n",
      " [   0    0    0    0    0    0    0    0    0    0    2    0    8    0\n",
      "    17   22    7   43  162    4  231  240]\n",
      " [   0    0    0    0    0    5    0    0    0    0   19    0    6    1\n",
      "     9  114   47  112  213    6  222  422]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     1   28   61  101  145    8  110  227]\n",
      " [   0    0    0    0    0    0    0    0    0    0    1    0    0    0\n",
      "     1   23   10  426  359   16  125  207]\n",
      " [   0    0    0    0    1    0    0    0    0    0    1    0    0    0\n",
      "    13   39   20   67 1752  101  443  530]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     1    1    3   15  347  251  192   80]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    1    0    7  277  110  730  218]\n",
      " [   0    1    0    0    0    0    0    2    0    0    0    0    0    0\n",
      "     8    0    1   98 1941  147 3180 5316]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\envs\\tf1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\anaconda3\\envs\\tf1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\anaconda3\\envs\\tf1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "RF = RandomForestClassifier(n_estimators=100)\n",
    "RF.fit(x_train,y_train)\n",
    "RF_Predprob=RF.predict_proba(x_test)\n",
    "RF_Pred=RF_Predprob.argmax(axis=1)\n",
    "printMetrics(y_test, RF_Pred)\n",
    "advMLEval(RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "LSVM = svm.SVC(kernel='linear',probability=True)\n",
    "LSVM.fit(x_train,y_train)\n",
    "LSVM_Predprob=LSVM.predict_proba(x_test)\n",
    "LSVM_Pred=LSVM_Predprob.argmax(axis=1)\n",
    "printMetrics(y_test, LSVM_Pred)\n",
    "advMLEval(LSVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "RSVM = svm.SVC(kernel='rbf',probability=True)\n",
    "RSVM.fit(x_train,y_train)\n",
    "RSVM_Predprob=RSVM.predict_proba(x_test)\n",
    "RSVM_Pred=RSVM_Predprob.argmax(axis=1)\n",
    "printMetrics(y_test, RSVM_Pred)\n",
    "advMLEval(RSVM)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}